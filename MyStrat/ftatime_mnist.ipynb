{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZdR1WXDEGxY",
        "outputId": "34c4f998-2ca0-4252-e4f7-424c286a9224"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obhFyleoEM9F",
        "outputId": "99c58edc-bb25-469f-b692-769941f695ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on cuda using PyTorch 2.3.1 and Flower 1.9.0\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple, NamedTuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import MNIST\n",
        "import time\n",
        "import flwr as fl\n",
        "from scipy import stats as st\n",
        "import json\n",
        "\n",
        "DEVICE = torch.device(\"cuda\")  # Try \"cuda\" to train on GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 84.5 GB  | Proc size: 508.9 MB\n",
            "GPU RAM Free: 10929MB | Used: 5239MB | Util  32% | Total 16376MB\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "   process = psutil.Process(os.getpid())\n",
        "   print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "   print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2L0M1hDEQ54",
        "outputId": "d7c63f7f-13e7-4f97-ff2d-97443878fa29"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "\n",
        "\n",
        "def load_datasets(num_clients: int):\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5, ))]\n",
        "    )\n",
        "    trainset = MNIST(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = MNIST(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "    partition_size = len(trainset) // num_clients\n",
        "    lengths = [partition_size] * num_clients\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
        "    testloader = DataLoader(testset, batch_size=32)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4q9gZPKEEVZ0"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "class ClientMetrics(NamedTuple):\n",
        "    epoch: int\n",
        "    loss: float\n",
        "    accuracy: float\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    metrics = []\n",
        "    for epoch in range(epochs):  # Use the passed 'epochs' variable here\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss.item()  # Make sure to call .item() to get the scalar value\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        metrics.append(ClientMetrics(epoch, epoch_loss, epoch_acc))\n",
        "        print(f\"Epoch {epoch}: train loss {epoch_loss:.6f}, accuracy {epoch_acc:.6f}\")\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DpDR8IdSEX0E"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        epochs = config.get(\"epochs\", 1)\n",
        "        start_time = time.time()  # Start time measurement\n",
        "        metrics = train(self.net, self.trainloader, epochs)\n",
        "        training_time = time.time() - start_time  # Calculate duration\n",
        "        print(f\"Training time for Client {self.cid}: {training_time:.2f} seconds\")\n",
        "        return get_parameters(self.net), len(self.trainloader), {\"training_time\": training_time, \"metrics\": json.dumps(metrics)}\n",
        "\n",
        "\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader).to_client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mSYL7mrZE21l"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Union\n",
        "\n",
        "from flwr.common import (\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    MetricsAggregationFn,\n",
        "    NDArrays,\n",
        "    Parameters,\n",
        "    Scalar,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "from flwr.server.client_manager import ClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
        "\n",
        "\n",
        "class FedCustom(fl.server.strategy.Strategy):\n",
        "    def __init__(\n",
        "        self,\n",
        "        fraction_fit: float = 1.0,\n",
        "        fraction_evaluate: float = 1.0,\n",
        "        min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2,\n",
        "        min_available_clients: int = 2,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.fraction_fit = fraction_fit\n",
        "        self.fraction_evaluate = fraction_evaluate\n",
        "        self.min_fit_clients = min_fit_clients\n",
        "        self.min_evaluate_clients = min_evaluate_clients\n",
        "        self.min_available_clients = min_available_clients\n",
        "        self.client_training_times = {}\n",
        "        self.client_metrics = {}\n",
        "    def __repr__(self) -> str:\n",
        "        return \"FedCustom\"\n",
        "\n",
        "    def initialize_parameters(\n",
        "        self, client_manager: ClientManager\n",
        "    ) -> Optional[Parameters]:\n",
        "        \"\"\"Initialize global model parameters.\"\"\"\n",
        "        net = Net()\n",
        "        ndarrays = get_parameters(net)\n",
        "        return fl.common.ndarrays_to_parameters(ndarrays)\n",
        "\n",
        "    def configure_fit(self, server_round: int, parameters: Parameters, client_manager: ClientManager):\n",
        "        sample_size, min_num_clients = self.num_fit_clients(client_manager.num_available())\n",
        "        clients = client_manager.sample(num_clients=sample_size, min_num_clients=min_num_clients)\n",
        "        epochs_sc = 10\n",
        "        \n",
        "\n",
        "        standard_config = {\"lr\": 0.001, \"epochs\": epochs_sc}\n",
        "        \n",
        "        fit_configurations = []\n",
        "        mode_time = []\n",
        "        \n",
        "        for client in clients:\n",
        "            last_time = self.client_training_times.get(client.cid, [0,])[-1] # Default to 0 if no time recorded # Yash has changed this as we now save last time of all epochs as key: value - cid: list of times\n",
        "            print(f\"This is ths last time not a fantasy {last_time}and {client.cid}habhhahah\")\n",
        "            \n",
        "            mode_time.append(round(last_time,2))\n",
        "            print(f\"this is tehb mode time {mode_time}\")\n",
        "\n",
        "        modest_value = st.mode(np.array(mode_time))\n",
        "        print(f\"Yeh h modest valueueueueu{modest_value}\")\n",
        "        print(f\"yeh h server round {server_round}\")\n",
        "        min_value, max_value= np.min(modest_value),np.max(modest_value)\n",
        "        print(f\"this is the min value {min_value} and this is the max value {max_value}\")\n",
        "        \n",
        "        if min_value == max_value:\n",
        "            epochs_hl = epochs_sc   \n",
        "        else:\n",
        "            epochs_hl = int(np.floor((max_value-min_value)/max_value * epochs_sc)) \n",
        "\n",
        "        higher_lr_config = {\"lr\": 0.0001, \"epochs\": epochs_hl}\n",
        "        print(f\"The epochs for the higher lr is {epochs_hl} and the epochs for the standard lr is {epochs_sc}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for client in clients:\n",
        "            # Choose config based on the previous training time\n",
        "            last_time = self.client_training_times.get(client.cid, [0,])[-1]  # Default to 0 if no time recorded # Yash has changed this as we now save last time of all epochs as key: value - cid: list of times\n",
        "            print(f\"This is the last time {last_time}\")\n",
        "            \n",
        "\n",
        "\n",
        "            config_to_use = standard_config if last_time < modest_value.mode else higher_lr_config\n",
        "            fit_configurations.append((client, FitIns(parameters, config_to_use)))\n",
        "\n",
        "        return fit_configurations\n",
        "    \n",
        "    def parse_metrics(self, cid, metrics: str): # this function has been added to parse the metrics from the client\n",
        "        client_data: List[ClientMetrics] = json.loads(metrics)\n",
        "        data_store = self.client_metrics.setdefault(cid, [])\n",
        "        last_epoch = len(data_store)\n",
        "        for data in client_data:\n",
        "            data_store.append(ClientMetrics(last_epoch, data[1], data[2]))\n",
        "            last_epoch += 1\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
        "        for client, fit_res in results:\n",
        "            # Update training times for each client\n",
        "            self.client_training_times.setdefault(client.cid, []).append(fit_res.metrics.get(\"training_time\", 0)) # Yash has changed this as we now save last time of all epochs as key: value - cid: list of times\n",
        "            self.parse_metrics(client.cid, fit_res.metrics.get(\"metrics\", None))\n",
        "        weights_results = [\n",
        "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "            for _, fit_res in results\n",
        "        ]\n",
        "        parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
        "        metrics_aggregated = {}\n",
        "        return parameters_aggregated, metrics_aggregated\n",
        "\n",
        "\n",
        "    def configure_evaluate(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
        "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
        "        if self.fraction_evaluate == 0.0:\n",
        "            return []\n",
        "        config = {}\n",
        "        evaluate_ins = EvaluateIns(parameters, config)\n",
        "\n",
        "        # Sample clients\n",
        "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        clients = client_manager.sample(\n",
        "            num_clients=sample_size, min_num_clients=min_num_clients\n",
        "        )\n",
        "\n",
        "        # Return client/config pairs\n",
        "        return [(client, evaluate_ins) for client in clients]\n",
        "\n",
        "    def aggregate_evaluate(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
        "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
        "\n",
        "        if not results:\n",
        "            return None, {}\n",
        "\n",
        "        loss_aggregated = weighted_loss_avg(\n",
        "            [\n",
        "                (evaluate_res.num_examples, evaluate_res.loss)\n",
        "                for _, evaluate_res in results\n",
        "            ]\n",
        "        )\n",
        "        metrics_aggregated = {}\n",
        "        return loss_aggregated, metrics_aggregated\n",
        "\n",
        "    def evaluate(\n",
        "        self, server_round: int, parameters: Parameters\n",
        "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "        \"\"\"Evaluate global model parameters using an evalua\n",
        "        tion function.\"\"\"\n",
        "\n",
        "        # Let's assume we won't perform the global model evaluation on the server side.\n",
        "        return None\n",
        "\n",
        "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
        "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
        "        num_clients = int(num_available_clients * self.fraction_fit)\n",
        "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
        "\n",
        "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
        "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
        "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
        "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if DEVICE.type == \"cuda\":\n",
        "#     # Use a single client to train the global model\n",
        "#     client_resources = { \"num_cpus\": 2} \n",
        "# client_resources = { \"num_cpus\": 2} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "if DEVICE.type == \"cuda\":\n",
        "    # Use a single client to train the global model\n",
        "    client_resources = {\"num_gpus\": .125, \"num_cpus\": 1} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvJM3bH4HDth",
        "outputId": "a273cb4a-ef0a-40e3-f789-e8f1f37366ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=1, no round_timeout\n"
          ]
        },
        {
          "ename": "Exception",
          "evalue": "The current node timed out during startup. This could happen because some of the Ray processes failed to startup.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\newflwr\\Lib\\site-packages\\ray\\_private\\node.py:339\u001b[0m, in \u001b[0;36mNode.__init__\u001b[1;34m(self, ray_params, head, shutdown_at_exit, spawn_reaper, connect_only, default_worker, ray_init_cluster)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m     \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_private\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcs_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plasma_store_socket_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m te:\n",
            "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\newflwr\\Lib\\site-packages\\ray\\_private\\services.py:464\u001b[0m, in \u001b[0;36mwait_for_node\u001b[1;34m(gcs_address, node_plasma_store_socket_name, timeout)\u001b[0m\n\u001b[0;32m    463\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m--> 464\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds while waiting for node to startup. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid not find socket name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_plasma_store_socket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in the list \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof object store socket names.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    468\u001b[0m )\n",
            "\u001b[1;31mTimeoutError\u001b[0m: Timed out after 60 seconds while waiting for node to startup. Did not find socket name tcp://127.0.0.1:61686 in the list of object store socket names.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m strategy \u001b[38;5;241m=\u001b[39m FedCustom()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# <-- pass the new strategy here\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\newflwr\\Lib\\site-packages\\flwr\\simulation\\app.py:226\u001b[0m, in \u001b[0;36mstart_simulation\u001b[1;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[0;32m    223\u001b[0m     ray\u001b[38;5;241m.\u001b[39mshutdown()\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Initialize Ray\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mray_init_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m cluster_resources \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mcluster_resources()\n\u001b[0;32m    228\u001b[0m log(\n\u001b[0;32m    229\u001b[0m     INFO,\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlower VCE: Ray initialized with resources: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m     cluster_resources,\n\u001b[0;32m    232\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\newflwr\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\newflwr\\Lib\\site-packages\\ray\\_private\\worker.py:1664\u001b[0m, in \u001b[0;36minit\u001b[1;34m(address, num_cpus, num_gpus, resources, labels, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, logging_config, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[0;32m   1631\u001b[0m     ray_params \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39m_private\u001b[38;5;241m.\u001b[39mparameter\u001b[38;5;241m.\u001b[39mRayParams(\n\u001b[0;32m   1632\u001b[0m         node_ip_address\u001b[38;5;241m=\u001b[39m_node_ip_address,\n\u001b[0;32m   1633\u001b[0m         object_ref_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1658\u001b[0m         node_name\u001b[38;5;241m=\u001b[39m_node_name,\n\u001b[0;32m   1659\u001b[0m     )\n\u001b[0;32m   1660\u001b[0m     \u001b[38;5;66;03m# Start the Ray processes. We set shutdown_at_exit=False because we\u001b[39;00m\n\u001b[0;32m   1661\u001b[0m     \u001b[38;5;66;03m# shutdown the node in the ray.shutdown call that happens in the atexit\u001b[39;00m\n\u001b[0;32m   1662\u001b[0m     \u001b[38;5;66;03m# handler. We still spawn a reaper process in case the atexit handler\u001b[39;00m\n\u001b[0;32m   1663\u001b[0m     \u001b[38;5;66;03m# isn't called.\u001b[39;00m\n\u001b[1;32m-> 1664\u001b[0m     _global_node \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_private\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mray_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mray_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshutdown_at_exit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspawn_reaper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mray_init_cluster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1672\u001b[0m     \u001b[38;5;66;03m# In this case, we are connecting to an existing cluster.\u001b[39;00m\n\u001b[0;32m   1673\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_cpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m num_gpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\newflwr\\Lib\\site-packages\\ray\\_private\\node.py:344\u001b[0m, in \u001b[0;36mNode.__init__\u001b[1;34m(self, ray_params, head, shutdown_at_exit, spawn_reaper, connect_only, default_worker, ray_init_cluster)\u001b[0m\n\u001b[0;32m    339\u001b[0m     ray\u001b[38;5;241m.\u001b[39m_private\u001b[38;5;241m.\u001b[39mservices\u001b[38;5;241m.\u001b[39mwait_for_node(\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcs_address,\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plasma_store_socket_name,\n\u001b[0;32m    342\u001b[0m     )\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m te:\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current node timed out during startup. This \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould happen because some of the Ray processes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed to startup.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    348\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mte\u001b[39;00m\n\u001b[0;32m    349\u001b[0m node_info \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39m_private\u001b[38;5;241m.\u001b[39mservices\u001b[38;5;241m.\u001b[39mget_node(\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcs_address,\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node_id,\n\u001b[0;32m    352\u001b[0m )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ray_params\u001b[38;5;241m.\u001b[39mnode_manager_port \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "\u001b[1;31mException\u001b[0m: The current node timed out during startup. This could happen because some of the Ray processes failed to startup."
          ]
        }
      ],
      "source": [
        "strategy = FedCustom()\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=10,\n",
        "    config=fl.server.ServerConfig(num_rounds=10),\n",
        "    strategy=strategy,  # <-- pass the new strategy here\n",
        "    client_resources=client_resources,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_metrics(client_metrics):\n",
        "    # client_metrics = strategy.client_metrics\n",
        "    client_ids = list(client_metrics.keys())\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    for cid in client_ids:\n",
        "        epochs = [metric.epoch for metric in client_metrics[cid]]\n",
        "        losses = [metric.loss for metric in client_metrics[cid]]\n",
        "        axs[0].plot(epochs, losses, label=f\"Client {cid}\")\n",
        "\n",
        "    axs[0].set_xlabel(\"Epoch\")\n",
        "    axs[0].set_ylabel(\"Loss\")\n",
        "    axs[0].legend()\n",
        "\n",
        "    for cid in client_ids:\n",
        "        epochs = [metric.epoch for metric in client_metrics[cid]]\n",
        "        accuracies = [metric.accuracy for metric in client_metrics[cid]]\n",
        "        axs[1].plot(epochs, accuracies, label=f\"Client {cid}\")\n",
        "\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].set_ylabel(\"Accuracy\")\n",
        "    axs[1].legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_metrics(strategy.client_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_times(client_training_times):\n",
        "    client_ids = list(client_training_times.keys())\n",
        "    num_rounds = len(client_training_times[client_ids[0]])\n",
        "\n",
        "    x = np.arange(num_rounds)  # Positions of the bars\n",
        "    bar_width = 0.05 # Width of bars\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    for i, client_id in enumerate(client_ids):\n",
        "        times = client_training_times[client_id]\n",
        "        ax.bar(x + i * bar_width, times, bar_width, label=client_id)\n",
        "\n",
        "    ax.set_xlabel(\"Round\")\n",
        "    ax.set_ylabel(\"Time (seconds)\")\n",
        "    ax.set_title(\"Client Training Times\")\n",
        "    ax.set_xticks(x + bar_width * round(len(client_ids) / 2))\n",
        "    ax.set_xticklabels(np.arange(1, num_rounds + 1))\n",
        "    ax.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_times(strategy.client_training_times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for a in strategy.client_metrics:\n",
        "    print(f\"Client {a} metrics: {len(strategy.client_metrics[a])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        start_time = time.time()  # Start time measurement\n",
        "        metrics = train(self.net, self.trainloader, epochs=10)\n",
        "        training_time = time.time() - start_time  # Calculate duration\n",
        "        return get_parameters(self.net), len(self.trainloader), {\"training_time\": training_time, \"metrics\": json.dumps(metrics)}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        print(f\"Client {self.cid} loss {loss}\")\n",
        "        print(f\"Client {self.cid} accuracy {accuracy}\")\n",
        "        \n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE) #Load Model from here\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader).to_client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FedAvgCustom(fl.server.strategy.FedAvg):\n",
        "    def __init__(\n",
        "        self,\n",
        "        fraction_fit = 1.0,\n",
        "        fraction_evaluate = 1.0,\n",
        "        min_fit_clients = 2,\n",
        "        min_evaluate_clients = 2,\n",
        "        min_available_clients = 2,\n",
        "    ):\n",
        "        super().__init__(fraction_fit = fraction_fit, fraction_evaluate = fraction_evaluate, min_fit_clients = min_fit_clients, min_evaluate_clients = min_evaluate_clients, min_available_clients = min_available_clients)\n",
        "        self.client_training_times = {}\n",
        "        self.client_metrics = {}\n",
        "\n",
        "    def parse_metrics(self, cid, metrics: str):\n",
        "        client_data: List[ClientMetrics] = json.loads(metrics)\n",
        "        data_store = self.client_metrics.setdefault(cid, [])\n",
        "        last_epoch = len(data_store)\n",
        "        for data in client_data:\n",
        "            data_store.append(ClientMetrics(last_epoch, data[1], data[2]))\n",
        "            last_epoch += 1\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
        "        for client, fit_res in results:\n",
        "            self.client_training_times.setdefault(client.cid, []).append(fit_res.metrics.get(\"training_time\", 0))\n",
        "            self.parse_metrics(client.cid, fit_res.metrics.get(\"metrics\", None))\n",
        "        weights_results = [\n",
        "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "            for _, fit_res in results\n",
        "        ]\n",
        "        parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
        "        metrics_aggregated = {}\n",
        "        return parameters_aggregated, metrics_aggregated\n",
        "\n",
        "# fl.simulation.start_simulation(\n",
        "#     client_fn=client_fn,\n",
        "#     num_clients=10,\n",
        "#     config=fl.server.ServerConfig(num_rounds=10),\n",
        "#     client_resources=client_resources,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2024-06-03 16:51:48,934 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2024-06-03 16:51:54,997 | app.py:180 | Flower VCE: Ray initialized with resources: {'object_store_memory': 25372973875.0, 'memory': 50745947751.0, 'node:127.0.0.1': 1.0, 'CPU': 32.0, 'GPU': 1.0}\n",
            "INFO flwr 2024-06-03 16:51:55,001 | server.py:86 | Initializing global parameters\n",
            "INFO flwr 2024-06-03 16:51:55,002 | server.py:273 | Requesting initial parameters from one random client\n",
            "INFO flwr 2024-06-03 16:51:57,564 | server.py:277 | Received initial parameters from one random client\n",
            "INFO flwr 2024-06-03 16:51:57,566 | server.py:88 | Evaluating initial parameters\n",
            "INFO flwr 2024-06-03 16:51:57,568 | server.py:101 | FL starting\n",
            "DEBUG flwr 2024-06-03 16:51:57,570 | server.py:218 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " pid=1176)\u001b[0m [Client 5] get_parameters\n",
            " pid=1176)\u001b[0m [Client 6] fit, config: {}\n",
            " pid=26192)\u001b[0m [Client 3] fit, config: {}\n",
            " pid=7204)\u001b[0m [Client 4] fit, config: {}\n",
            " pid=20224)\u001b[0m [Client 8] fit, config: {}\n",
            " pid=1176)\u001b[0m Epoch 0: train loss 0.031406, accuracy 0.666111\n",
            " pid=1176)\u001b[0m Epoch 1: train loss 0.008640, accuracy 0.913704\n",
            " pid=7204)\u001b[0m Epoch 0: train loss 0.032170, accuracy 0.655741\n",
            " pid=1176)\u001b[0m Epoch 2: train loss 0.005622, accuracy 0.942778\n",
            " pid=26192)\u001b[0m Epoch 0: train loss 0.031131, accuracy 0.674074\n",
            " pid=20224)\u001b[0m Epoch 0: train loss 0.032145, accuracy 0.666667\n",
            " pid=7204)\u001b[0m Epoch 1: train loss 0.007931, accuracy 0.923519\n",
            " pid=1176)\u001b[0m Epoch 3: train loss 0.004063, accuracy 0.960741\n",
            " pid=26192)\u001b[0m Epoch 1: train loss 0.008260, accuracy 0.919815\n",
            " pid=20224)\u001b[0m Epoch 1: train loss 0.009373, accuracy 0.907963\n",
            " pid=7204)\u001b[0m Epoch 2: train loss 0.005402, accuracy 0.945000\n",
            " pid=26192)\u001b[0m Epoch 2: train loss 0.005360, accuracy 0.947593\n",
            " pid=1176)\u001b[0m Epoch 4: train loss 0.003442, accuracy 0.963333\n",
            " pid=1176)\u001b[0m [Client 5] fit, config: {}\n",
            " pid=20224)\u001b[0m Epoch 2: train loss 0.005642, accuracy 0.942407\n",
            " pid=7204)\u001b[0m Epoch 3: train loss 0.004041, accuracy 0.959630\n",
            " pid=26192)\u001b[0m Epoch 3: train loss 0.003964, accuracy 0.957963\n",
            " pid=20224)\u001b[0m Epoch 3: train loss 0.004124, accuracy 0.957963\n",
            " pid=1176)\u001b[0m Epoch 0: train loss 0.031781, accuracy 0.671852\n",
            " pid=7204)\u001b[0m Epoch 4: train loss 0.003572, accuracy 0.962407\n",
            " pid=7204)\u001b[0m [Client 0] fit, config: {}\n",
            " pid=26192)\u001b[0m Epoch 4: train loss 0.003113, accuracy 0.967778\n",
            " pid=26192)\u001b[0m [Client 9] fit, config: {}\n",
            " pid=20224)\u001b[0m Epoch 4: train loss 0.003168, accuracy 0.967407\n",
            " pid=20224)\u001b[0m [Client 7] fit, config: {}\n",
            " pid=1176)\u001b[0m Epoch 1: train loss 0.009015, accuracy 0.915556\n",
            " pid=7204)\u001b[0m Epoch 0: train loss 0.031044, accuracy 0.684074\n",
            " pid=26192)\u001b[0m Epoch 0: train loss 0.030077, accuracy 0.686667\n",
            " pid=20224)\u001b[0m Epoch 0: train loss 0.032121, accuracy 0.667222\n",
            " pid=1176)\u001b[0m Epoch 2: train loss 0.005861, accuracy 0.943148\n",
            " pid=7204)\u001b[0m Epoch 1: train loss 0.008374, accuracy 0.918333\n",
            " pid=26192)\u001b[0m Epoch 1: train loss 0.008571, accuracy 0.917593\n",
            " pid=20224)\u001b[0m Epoch 1: train loss 0.009432, accuracy 0.900741\n",
            " pid=1176)\u001b[0m Epoch 3: train loss 0.004415, accuracy 0.958148\n",
            " pid=7204)\u001b[0m Epoch 2: train loss 0.005233, accuracy 0.948704\n",
            " pid=26192)\u001b[0m Epoch 2: train loss 0.005907, accuracy 0.940741\n",
            " pid=20224)\u001b[0m Epoch 2: train loss 0.005872, accuracy 0.942222\n",
            " pid=1176)\u001b[0m Epoch 4: train loss 0.003810, accuracy 0.962593\n",
            " pid=1176)\u001b[0m [Client 1] fit, config: {}\n",
            " pid=7204)\u001b[0m Epoch 3: train loss 0.003884, accuracy 0.960185\n",
            " pid=26192)\u001b[0m Epoch 3: train loss 0.004411, accuracy 0.958148\n",
            " pid=20224)\u001b[0m Epoch 3: train loss 0.004202, accuracy 0.956481\n",
            " pid=7204)\u001b[0m Epoch 4: train loss 0.003187, accuracy 0.968333\n",
            " pid=7204)\u001b[0m [Client 2] fit, config: {}\n",
            " pid=1176)\u001b[0m Epoch 0: train loss 0.030537, accuracy 0.686667\n",
            " pid=26192)\u001b[0m Epoch 4: train loss 0.003525, accuracy 0.965370\n",
            " pid=20224)\u001b[0m Epoch 4: train loss 0.003358, accuracy 0.964444\n",
            " pid=7204)\u001b[0m Epoch 0: train loss 0.030530, accuracy 0.682963\n",
            " pid=1176)\u001b[0m Epoch 1: train loss 0.008099, accuracy 0.922222\n",
            " pid=7204)\u001b[0m Epoch 1: train loss 0.008661, accuracy 0.915185\n",
            " pid=1176)\u001b[0m Epoch 2: train loss 0.005435, accuracy 0.944815\n",
            " pid=7204)\u001b[0m Epoch 2: train loss 0.005231, accuracy 0.950000\n",
            " pid=1176)\u001b[0m Epoch 3: train loss 0.004079, accuracy 0.958333\n",
            " pid=7204)\u001b[0m Epoch 3: train loss 0.003828, accuracy 0.961667\n",
            " pid=1176)\u001b[0m Epoch 4: train loss 0.003213, accuracy 0.966481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-06-03 16:53:15,510 | server.py:232 | fit_round 1 received 10 results and 0 failures\n",
            "WARNING flwr 2024-06-03 16:53:15,545 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2024-06-03 16:53:15,547 | server.py:168 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " pid=7204)\u001b[0m Epoch 4: train loss 0.003275, accuracy 0.964630\n",
            " pid=7204)\u001b[0m [Client 4] evaluate, config: {}\n",
            " pid=1176)\u001b[0m [Client 7] evaluate, config: {}\n",
            " pid=26192)\u001b[0m [Client 0] evaluate, config: {}\n",
            " pid=7204)\u001b[0m Client 4 loss 0.006275855886439482\n",
            " pid=7204)\u001b[0m Client 4 accuracy 0.94\n",
            " pid=20224)\u001b[0m [Client 5] evaluate, config: {}\n",
            " pid=7204)\u001b[0m [Client 3] evaluate, config: {}\n",
            " pid=1176)\u001b[0m Client 7 loss 0.005566535132626693\n",
            " pid=1176)\u001b[0m Client 7 accuracy 0.9416666666666667\n",
            " pid=1176)\u001b[0m [Client 8] evaluate, config: {}\n",
            " pid=26192)\u001b[0m Client 0 loss 0.006947518636782964\n",
            " pid=26192)\u001b[0m Client 0 accuracy 0.95\n",
            " pid=26192)\u001b[0m [Client 6] evaluate, config: {}\n",
            " pid=7204)\u001b[0m Client 3 loss 0.0055223917216062545\n",
            " pid=7204)\u001b[0m Client 3 accuracy 0.955\n",
            " pid=20224)\u001b[0m Client 5 loss 0.005880148770908515\n",
            " pid=20224)\u001b[0m Client 5 accuracy 0.95\n",
            " pid=7204)\u001b[0m [Client 2] evaluate, config: {}\n",
            " pid=20224)\u001b[0m [Client 9] evaluate, config: {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-06-03 16:53:17,320 | server.py:182 | evaluate_round 1 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " pid=1176)\u001b[0m Client 8 loss 0.005975093450397253\n",
            " pid=1176)\u001b[0m Client 8 accuracy 0.9483333333333334\n",
            " pid=26192)\u001b[0m Client 6 loss 0.006098443232476711\n",
            " pid=26192)\u001b[0m Client 6 accuracy 0.955\n",
            " pid=1176)\u001b[0m [Client 1] evaluate, config: {}\n",
            " pid=7204)\u001b[0m Client 2 loss 0.005935466438531875\n",
            " pid=7204)\u001b[0m Client 2 accuracy 0.9433333333333334\n",
            " pid=20224)\u001b[0m Client 9 loss 0.00602887732287248\n",
            " pid=20224)\u001b[0m Client 9 accuracy 0.945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING flwr 2024-06-03 16:53:17,323 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2024-06-03 16:53:17,326 | server.py:218 | fit_round 2: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " pid=1176)\u001b[0m Client 1 loss 0.005294886069993178\n",
            " pid=1176)\u001b[0m Client 1 accuracy 0.9566666666666667\n",
            " pid=1176)\u001b[0m [Client 7] fit, config: {}\n",
            " pid=20224)\u001b[0m [Client 8] fit, config: {}\n",
            " pid=7204)\u001b[0m [Client 0] fit, config: {}\n",
            " pid=26192)\u001b[0m [Client 3] fit, config: {}\n",
            " pid=1176)\u001b[0m Epoch 0: train loss 0.004475, accuracy 0.955926\n",
            " pid=7204)\u001b[0m Epoch 0: train loss 0.004789, accuracy 0.950000\n",
            " pid=20224)\u001b[0m Epoch 0: train loss 0.004744, accuracy 0.952037\n",
            " pid=26192)\u001b[0m Epoch 0: train loss 0.004373, accuracy 0.956667\n",
            " pid=7204)\u001b[0m Epoch 1: train loss 0.003340, accuracy 0.965556\n",
            " pid=1176)\u001b[0m Epoch 1: train loss 0.003050, accuracy 0.968333\n",
            " pid=20224)\u001b[0m Epoch 1: train loss 0.003291, accuracy 0.964815\n",
            " pid=26192)\u001b[0m Epoch 1: train loss 0.003187, accuracy 0.967407\n",
            " pid=7204)\u001b[0m Epoch 2: train loss 0.002456, accuracy 0.972778\n",
            " pid=26192)\u001b[0m Epoch 2: train loss 0.002514, accuracy 0.973704\n",
            " pid=1176)\u001b[0m Epoch 2: train loss 0.002352, accuracy 0.975556\n",
            " pid=20224)\u001b[0m Epoch 2: train loss 0.002354, accuracy 0.973889\n",
            " pid=7204)\u001b[0m Epoch 3: train loss 0.001980, accuracy 0.980000\n",
            " pid=26192)\u001b[0m Epoch 3: train loss 0.001760, accuracy 0.980556\n",
            " pid=1176)\u001b[0m Epoch 3: train loss 0.001567, accuracy 0.984444\n",
            " pid=20224)\u001b[0m Epoch 3: train loss 0.001871, accuracy 0.982407\n",
            " pid=7204)\u001b[0m Epoch 4: train loss 0.001365, accuracy 0.984444\n",
            " pid=7204)\u001b[0m [Client 5] fit, config: {}\n",
            " pid=26192)\u001b[0m Epoch 4: train loss 0.001604, accuracy 0.983519\n",
            " pid=26192)\u001b[0m [Client 6] fit, config: {}\n",
            " pid=20224)\u001b[0m Epoch 4: train loss 0.001168, accuracy 0.988148\n",
            " pid=20224)\u001b[0m [Client 2] fit, config: {}\n",
            " pid=1176)\u001b[0m Epoch 4: train loss 0.001315, accuracy 0.985556\n",
            " pid=1176)\u001b[0m [Client 1] fit, config: {}\n",
            " pid=7204)\u001b[0m Epoch 0: train loss 0.005133, accuracy 0.948704\n",
            " pid=26192)\u001b[0m Epoch 0: train loss 0.004692, accuracy 0.950926\n",
            " pid=20224)\u001b[0m Epoch 0: train loss 0.004544, accuracy 0.954630\n",
            " pid=1176)\u001b[0m Epoch 0: train loss 0.004341, accuracy 0.957407\n",
            " pid=7204)\u001b[0m Epoch 1: train loss 0.003344, accuracy 0.966852\n",
            " pid=26192)\u001b[0m Epoch 1: train loss 0.003364, accuracy 0.965000\n",
            " pid=20224)\u001b[0m Epoch 1: train loss 0.003105, accuracy 0.969074\n",
            " pid=1176)\u001b[0m Epoch 1: train loss 0.003136, accuracy 0.968333\n",
            " pid=7204)\u001b[0m Epoch 2: train loss 0.002544, accuracy 0.972593\n",
            " pid=26192)\u001b[0m Epoch 2: train loss 0.002387, accuracy 0.977407\n",
            " pid=20224)\u001b[0m Epoch 2: train loss 0.002409, accuracy 0.976481\n",
            " pid=1176)\u001b[0m Epoch 2: train loss 0.002043, accuracy 0.979444\n",
            " pid=7204)\u001b[0m Epoch 3: train loss 0.001925, accuracy 0.981481\n",
            " pid=26192)\u001b[0m Epoch 3: train loss 0.001665, accuracy 0.982778\n",
            " pid=20224)\u001b[0m Epoch 3: train loss 0.001742, accuracy 0.983148\n",
            " pid=1176)\u001b[0m Epoch 3: train loss 0.001910, accuracy 0.981481\n",
            " pid=7204)\u001b[0m Epoch 4: train loss 0.001315, accuracy 0.985741\n",
            " pid=7204)\u001b[0m [Client 4] fit, config: {}\n",
            " pid=20224)\u001b[0m Epoch 4: train loss 0.001560, accuracy 0.984630\n",
            " pid=26192)\u001b[0m Epoch 4: train loss 0.001661, accuracy 0.982037\n",
            " pid=20224)\u001b[0m [Client 9] fit, config: {}\n",
            " pid=1176)\u001b[0m Epoch 4: train loss 0.001209, accuracy 0.987778\n",
            " pid=7204)\u001b[0m Epoch 0: train loss 0.004697, accuracy 0.952593\n",
            " pid=20224)\u001b[0m Epoch 0: train loss 0.004644, accuracy 0.954630\n",
            " pid=7204)\u001b[0m Epoch 1: train loss 0.003265, accuracy 0.964815\n",
            " pid=20224)\u001b[0m Epoch 1: train loss 0.003331, accuracy 0.967037\n",
            " pid=7204)\u001b[0m Epoch 2: train loss 0.002453, accuracy 0.974630\n",
            " pid=20224)\u001b[0m Epoch 2: train loss 0.002597, accuracy 0.975556\n",
            " pid=7204)\u001b[0m Epoch 3: train loss 0.001853, accuracy 0.979074\n",
            " pid=20224)\u001b[0m Epoch 3: train loss 0.001900, accuracy 0.979074\n",
            " pid=7204)\u001b[0m Epoch 4: train loss 0.001244, accuracy 0.985741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-06-03 16:54:09,148 | server.py:232 | fit_round 2 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-06-03 16:54:09,181 | server.py:168 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " pid=20224)\u001b[0m Epoch 4: train loss 0.001697, accuracy 0.981667\n",
            " pid=20224)\u001b[0m [Client 8] evaluate, config: {}\n",
            " pid=1176)\u001b[0m [Client 7] evaluate, config: {}\n",
            " pid=26192)\u001b[0m [Client 1] evaluate, config: {}\n",
            " pid=7204)\u001b[0m [Client 3] evaluate, config: {}\n",
            " pid=20224)\u001b[0m Client 8 loss 0.0013796642417825448\n",
            " pid=20224)\u001b[0m Client 8 accuracy 0.9866666666666667\n",
            " pid=20224)\u001b[0m [Client 2] evaluate, config: {}\n",
            " pid=1176)\u001b[0m Client 7 loss 0.0018857226961214717\n",
            " pid=1176)\u001b[0m Client 7 accuracy 0.9816666666666667\n",
            " pid=26192)\u001b[0m Client 1 loss 0.002319714394398034\n",
            " pid=26192)\u001b[0m Client 1 accuracy 0.975\n",
            " pid=7204)\u001b[0m Client 3 loss 0.002454152571541878\n",
            " pid=7204)\u001b[0m Client 3 accuracy 0.9783333333333334\n",
            " pid=20224)\u001b[0m Client 2 loss 0.0016611025338837257\n",
            " pid=20224)\u001b[0m Client 2 accuracy 0.98\n",
            " pid=1176)\u001b[0m [Client 5] evaluate, config: {}\n",
            " pid=26192)\u001b[0m [Client 4] evaluate, config: {}\n",
            " pid=7204)\u001b[0m [Client 0] evaluate, config: {}\n",
            " pid=20224)\u001b[0m [Client 6] evaluate, config: {}\n",
            " pid=1176)\u001b[0m Client 5 loss 0.0024994818629541743\n",
            " pid=1176)\u001b[0m Client 5 accuracy 0.9766666666666667\n",
            " pid=26192)\u001b[0m Client 4 loss 0.002227524443975805\n",
            " pid=26192)\u001b[0m Client 4 accuracy 0.975\n",
            " pid=7204)\u001b[0m Client 0 loss 0.0031525307215633804\n",
            " pid=7204)\u001b[0m Client 0 accuracy 0.9766666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-06-03 16:54:10,791 | server.py:182 | evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-06-03 16:54:10,793 | server.py:218 | fit_round 3: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " pid=7204)\u001b[0m [Client 9] evaluate, config: {}\n",
            " pid=20224)\u001b[0m Client 6 loss 0.002475445768213831\n",
            " pid=20224)\u001b[0m Client 6 accuracy 0.9733333333333334\n",
            " pid=7204)\u001b[0m Client 9 loss 0.002454910888336599\n",
            " pid=7204)\u001b[0m Client 9 accuracy 0.9783333333333334\n",
            " pid=7204)\u001b[0m [Client 7] fit, config: {}\n",
            " pid=20224)\u001b[0m [Client 1] fit, config: {}\n",
            " pid=26192)\u001b[0m [Client 9] fit, config: {}\n",
            " pid=1176)\u001b[0m [Client 5] fit, config: {}\n",
            " pid=7204)\u001b[0m Epoch 0: train loss 0.002740, accuracy 0.972963\n",
            " pid=20224)\u001b[0m Epoch 0: train loss 0.002576, accuracy 0.973889\n",
            " pid=26192)\u001b[0m Epoch 0: train loss 0.003089, accuracy 0.970926\n",
            " pid=1176)\u001b[0m Epoch 0: train loss 0.003157, accuracy 0.970000\n",
            " pid=7204)\u001b[0m Epoch 1: train loss 0.001792, accuracy 0.982222\n",
            " pid=26192)\u001b[0m Epoch 1: train loss 0.001789, accuracy 0.982407\n",
            " pid=20224)\u001b[0m Epoch 1: train loss 0.001681, accuracy 0.982037\n",
            " pid=1176)\u001b[0m Epoch 1: train loss 0.001860, accuracy 0.982778\n",
            " pid=7204)\u001b[0m Epoch 2: train loss 0.001289, accuracy 0.987407\n",
            " pid=26192)\u001b[0m Epoch 2: train loss 0.001422, accuracy 0.985185\n",
            " pid=20224)\u001b[0m Epoch 2: train loss 0.001322, accuracy 0.985185\n",
            " pid=1176)\u001b[0m Epoch 2: train loss 0.001286, accuracy 0.986481\n",
            " pid=7204)\u001b[0m Epoch 3: train loss 0.001013, accuracy 0.989074\n",
            " pid=26192)\u001b[0m Epoch 3: train loss 0.001092, accuracy 0.989074\n",
            " pid=20224)\u001b[0m Epoch 3: train loss 0.000833, accuracy 0.992778\n",
            " pid=1176)\u001b[0m Epoch 3: train loss 0.001137, accuracy 0.987037\n",
            " pid=26192)\u001b[0m Epoch 4: train loss 0.000747, accuracy 0.992037\n",
            " pid=7204)\u001b[0m Epoch 4: train loss 0.000486, accuracy 0.996111\n",
            " pid=7204)\u001b[0m [Client 0] fit, config: {}\n",
            " pid=20224)\u001b[0m Epoch 4: train loss 0.000820, accuracy 0.992037\n",
            " pid=20224)\u001b[0m [Client 6] fit, config: {}\n",
            " pid=26192)\u001b[0m [Client 8] fit, config: {}\n",
            " pid=1176)\u001b[0m Epoch 4: train loss 0.000663, accuracy 0.993889\n",
            " pid=1176)\u001b[0m [Client 3] fit, config: {}\n",
            " pid=7204)\u001b[0m Epoch 0: train loss 0.002783, accuracy 0.970926\n",
            " pid=26192)\u001b[0m Epoch 0: train loss 0.002745, accuracy 0.968889\n",
            " pid=20224)\u001b[0m Epoch 0: train loss 0.002791, accuracy 0.971852\n",
            " pid=1176)\u001b[0m Epoch 0: train loss 0.002874, accuracy 0.974074\n",
            " pid=7204)\u001b[0m Epoch 1: train loss 0.001978, accuracy 0.979259\n",
            " pid=20224)\u001b[0m Epoch 1: train loss 0.001878, accuracy 0.980741\n",
            " pid=26192)\u001b[0m Epoch 1: train loss 0.001752, accuracy 0.982407\n",
            " pid=1176)\u001b[0m Epoch 1: train loss 0.001768, accuracy 0.981852\n",
            " pid=7204)\u001b[0m Epoch 2: train loss 0.001345, accuracy 0.985556\n",
            " pid=20224)\u001b[0m Epoch 2: train loss 0.001378, accuracy 0.984815\n",
            " pid=26192)\u001b[0m Epoch 2: train loss 0.001100, accuracy 0.988148\n",
            " pid=1176)\u001b[0m Epoch 2: train loss 0.001223, accuracy 0.989074\n",
            " pid=7204)\u001b[0m Epoch 3: train loss 0.000787, accuracy 0.991481\n",
            " pid=20224)\u001b[0m Epoch 3: train loss 0.000922, accuracy 0.992593\n",
            " pid=26192)\u001b[0m Epoch 3: train loss 0.000864, accuracy 0.990370\n",
            " pid=1176)\u001b[0m Epoch 3: train loss 0.000986, accuracy 0.991296\n",
            " pid=7204)\u001b[0m Epoch 4: train loss 0.000723, accuracy 0.990556\n",
            " pid=7204)\u001b[0m [Client 2] fit, config: {}\n",
            " pid=20224)\u001b[0m Epoch 4: train loss 0.000901, accuracy 0.990556\n",
            " pid=20224)\u001b[0m [Client 4] fit, config: {}\n",
            " pid=26192)\u001b[0m Epoch 4: train loss 0.000818, accuracy 0.991667\n",
            " pid=1176)\u001b[0m Epoch 4: train loss 0.000760, accuracy 0.992407\n",
            " pid=7204)\u001b[0m Epoch 0: train loss 0.002606, accuracy 0.975741\n",
            " pid=20224)\u001b[0m Epoch 0: train loss 0.003113, accuracy 0.969630\n",
            " pid=7204)\u001b[0m Epoch 1: train loss 0.001640, accuracy 0.983889\n",
            " pid=20224)\u001b[0m Epoch 1: train loss 0.001702, accuracy 0.982963\n",
            " pid=7204)\u001b[0m Epoch 2: train loss 0.001343, accuracy 0.987407\n",
            " pid=20224)\u001b[0m Epoch 2: train loss 0.001474, accuracy 0.986667\n",
            " pid=7204)\u001b[0m Epoch 3: train loss 0.000749, accuracy 0.992407\n",
            " pid=20224)\u001b[0m Epoch 3: train loss 0.000762, accuracy 0.990000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-06-03 16:55:01,435 | server.py:232 | fit_round 3 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-06-03 16:55:01,466 | server.py:168 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " pid=7204)\u001b[0m Epoch 4: train loss 0.000771, accuracy 0.991852\n",
            " pid=20224)\u001b[0m Epoch 4: train loss 0.000829, accuracy 0.990556\n",
            " pid=20224)\u001b[0m [Client 0] evaluate, config: {}\n",
            " pid=7204)\u001b[0m [Client 2] evaluate, config: {}\n",
            " pid=20224)\u001b[0m Client 0 loss 0.002689745311048076\n",
            " pid=20224)\u001b[0m Client 0 accuracy 0.9766666666666667\n",
            " pid=7204)\u001b[0m Client 2 loss 0.0013351145418710076\n",
            " pid=7204)\u001b[0m Client 2 accuracy 0.98\n",
            " pid=20224)\u001b[0m [Client 9] evaluate, config: {}\n",
            " pid=20224)\u001b[0m Client 9 loss 0.0017798811106937743\n",
            " pid=20224)\u001b[0m Client 9 accuracy 0.9766666666666667\n",
            " pid=20224)\u001b[0m [Client 6] evaluate, config: {}\n",
            " pid=1176)\u001b[0m [Client 3] evaluate, config: {}\n",
            " pid=26192)\u001b[0m [Client 7] evaluate, config: {}\n",
            " pid=7204)\u001b[0m [Client 4] evaluate, config: {}\n",
            " pid=26192)\u001b[0m Client 7 loss 0.0015654092175342764\n",
            " pid=26192)\u001b[0m Client 7 accuracy 0.98\n",
            " pid=7204)\u001b[0m Client 4 loss 0.0017429726864793338\n",
            " pid=7204)\u001b[0m Client 4 accuracy 0.9833333333333333\n",
            " pid=20224)\u001b[0m Client 6 loss 0.0023496932164319634\n",
            " pid=20224)\u001b[0m Client 6 accuracy 0.9783333333333334\n",
            " pid=20224)\u001b[0m [Client 8] evaluate, config: {}\n",
            " pid=1176)\u001b[0m Client 3 loss 0.002221985572129294\n",
            " pid=1176)\u001b[0m Client 3 accuracy 0.9816666666666667\n",
            " pid=26192)\u001b[0m [Client 5] evaluate, config: {}\n",
            " pid=7204)\u001b[0m [Client 1] evaluate, config: {}\n",
            " pid=20224)\u001b[0m Client 8 loss 0.0012055746780970367\n",
            " pid=20224)\u001b[0m Client 8 accuracy 0.9883333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-06-03 16:55:03,392 | server.py:182 | evaluate_round 3 received 10 results and 0 failures\n",
            "INFO flwr 2024-06-03 16:55:03,394 | server.py:147 | FL finished in 185.8248713999999\n",
            "INFO flwr 2024-06-03 16:55:03,397 | app.py:218 | app_fit: losses_distributed [(1, 0.0059525216662635405), (2, 0.0022510250122771444), (3, 0.0019461998325896275)]\n",
            "INFO flwr 2024-06-03 16:55:03,399 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2024-06-03 16:55:03,400 | app.py:220 | app_fit: metrics_distributed {}\n",
            "INFO flwr 2024-06-03 16:55:03,402 | app.py:221 | app_fit: losses_centralized []\n",
            "INFO flwr 2024-06-03 16:55:03,405 | app.py:222 | app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.0059525216662635405\n",
              "\tround 2: 0.0022510250122771444\n",
              "\tround 3: 0.0019461998325896275"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " pid=26192)\u001b[0m Client 5 loss 0.00248527233673182\n",
            " pid=26192)\u001b[0m Client 5 accuracy 0.98\n",
            " pid=7204)\u001b[0m Client 1 loss 0.0020863496548796925\n",
            " pid=7204)\u001b[0m Client 1 accuracy 0.98\n"
          ]
        }
      ],
      "source": [
        "strategy_fed_avg = FedAvgCustom()\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=10,\n",
        "    config=fl.server.ServerConfig(num_rounds=10),\n",
        "    client_resources=client_resources,\n",
        "    strategy=strategy_fed_avg,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_metrics(strategy_fed_avg.client_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_times(strategy_fed_avg.client_training_times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

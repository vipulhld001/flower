{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZdR1WXDEGxY",
    "outputId": "34c4f998-2ca0-4252-e4f7-424c286a9224"
   },
   "outputs": [],
   "source": [
    "!pip install -q flwr[simulation] torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obhFyleoEM9F",
    "outputId": "99c58edc-bb25-469f-b692-769941f695ce"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "import time\n",
    "import flwr as fl\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")  # Try \"cuda\" to train on GPU\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    "   process = psutil.Process(os.getpid())\n",
    "   print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "   print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T2L0M1hDEQ54",
    "outputId": "d7c63f7f-13e7-4f97-ff2d-97443878fa29"
   },
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "\n",
    "\n",
    "def load_datasets(num_clients: int):\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    partition_size = len(trainset) // num_clients\n",
    "    lengths = [partition_size] * num_clients\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4q9gZPKEEVZ0"
   },
   "outputs": [],
   "source": [
    "from multiprocessing.connection import Client\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):  # Use the passed 'epochs' variable here\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item()  # Make sure to call .item() to get the scalar value\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        address = ('localhost', 6000)\n",
    "        try:\n",
    "            with Client(address, authkey=b'ri3uhisd') as conn:\n",
    "                conn.send_bytes(f'{cid}:{epoch}:{epoch_loss}:{epoch_acc}'.encode('utf-8'))\n",
    "        except:\n",
    "            print(f\"couldn't send data {cid}:{epoch}:{epoch_loss}:{epoch_acc}\")\n",
    "        print(f\"Epoch {epoch}: train loss {epoch_loss:.6f}, accuracy {epoch_acc:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpDR8IdSEX0E"
   },
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        epochs = config.get(\"epochs\", 1)\n",
    "        start_time = time.time()  # Start time measurement\n",
    "        train(self.net, self.trainloader, epochs)\n",
    "        training_time = time.time() - start_time  # Calculate duration\n",
    "        address = ('localhost', 6000)\n",
    "        try:\n",
    "            with Client(address, authkey=b'ri3uhisd') as conn:\n",
    "                conn.send_bytes(f'{self.cid}:{training_time}'.encode('utf-8'))\n",
    "        except Exception as err:\n",
    "            print(f\"couldn't send data {self.cid}:{training_time}\")\n",
    "            print(err)\n",
    "        print(f\"Training time for Client {self.cid}: {training_time:.2f} seconds\")\n",
    "        return get_parameters(self.net), len(self.trainloader), {\"training_time\": training_time}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "    # def setup_multiprocess_client(self):\n",
    "    #     address = ('localhost', 6000)\n",
    "    #     self.conn = Client(address, authkey=b'ri3uhisd')\n",
    "\n",
    "    # def __del__(self):\n",
    "    #     self.conn.close()\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSYL7mrZE21l"
   },
   "outputs": [],
   "source": [
    "from typing import Callable, Union\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    MetricsAggregationFn,\n",
    "    NDArrays,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "\n",
    "class FedCustom(fl.server.strategy.Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.client_training_times = {}\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedCustom\"\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        return fl.common.ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    def configure_fit(self, server_round: int, parameters: Parameters, client_manager: ClientManager):\n",
    "        sample_size, min_num_clients = self.num_fit_clients(client_manager.num_available())\n",
    "        clients = client_manager.sample(num_clients=sample_size, min_num_clients=min_num_clients)\n",
    "        epochs_sc = 3\n",
    "        epochs_hl = 2\n",
    "\n",
    "        standard_config = {\"lr\": 0.001, \"epochs\": epochs_sc}\n",
    "        higher_lr_config = {\"lr\": 0.0001, \"epochs\": epochs_hl}\n",
    "        fit_configurations = []\n",
    "\n",
    "        for client in clients:\n",
    "            # Choose config based on the previous training time\n",
    "            last_time = self.client_training_times.get(client.cid, 0)  # Default to 0 if no time recorded\n",
    "            print(f\"This is the last time {last_time}\")\n",
    "            \n",
    "\n",
    "\n",
    "            config_to_use = standard_config if last_time < 13.8 else higher_lr_config\n",
    "            fit_configurations.append((client, FitIns(parameters, config_to_use)))\n",
    "\n",
    "        return fit_configurations\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "        for client, fit_res in results:\n",
    "            # Update training times for each client\n",
    "            self.client_training_times[client.cid] = fit_res.metrics.get(\"training_time\", 0)\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "        parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
    "        metrics_aggregated = {}\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate global model parameters using an evalua\n",
    "        tion function.\"\"\"\n",
    "\n",
    "        # Let's assume we won't perform the global model evaluation on the server side.\n",
    "        return None\n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVICE.type == \"cuda\":\n",
    "    # Use a single client to train the global model\n",
    "    client_resources = {\"num_gpus\": .25, \"num_cpus\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvJM3bH4HDth",
    "outputId": "a273cb4a-ef0a-40e3-f789-e8f1f37366ce"
   },
   "outputs": [],
   "source": [
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    strategy=FedCustom(),  # <-- pass the new strategy here\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = ('localhost', 6000)\n",
    "with Client(address, authkey=b'ri3uhisd') as conn:\n",
    "    conn.send_bytes('12455:2:12.3453053:12.3431'.encode('utf-8'))\n",
    "with Client(address, authkey=b'ri3uhisd') as conn:\n",
    "    conn.send_bytes('34345:3:64.123123:87.123123'.encode('utf-8'))\n",
    "with Client(address, authkey=b'ri3uhisd') as conn:\n",
    "    conn.send_bytes('37123:4:23:34.343343423234'.encode('utf-8'))\n",
    "with Client(address, authkey=b'ri3uhisd') as conn:\n",
    "    conn.send_bytes('37123:10.023823'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = ('localhost', 6000)\n",
    "with Client(address, authkey=b'ri3uhisd') as conn:\n",
    "    conn.send_bytes('exit'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-06-26 20:01:38,532 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2024-06-26 20:01:43,167\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "INFO flwr 2024-06-26 20:01:45,282 | app.py:180 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'accelerator_type:RTX': 1.0, 'node:__internal_head__': 1.0, 'memory': 66836512973.0, 'object_store_memory': 32929934131.0, 'node:127.0.0.1': 1.0, 'CPU': 32.0}\n",
      "INFO flwr 2024-06-26 20:01:45,284 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2024-06-26 20:01:45,284 | server.py:273 | Requesting initial parameters from one random client\n",
      "ERROR flwr 2024-06-26 20:01:50,687 | ray_client_proxy.py:72 | \u001b[36mray::launch_and_get_parameters()\u001b[39m (pid=40416, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_client_proxy.py\", line 136, in launch_and_get_parameters\n",
      "    return maybe_call_get_parameters(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\client.py\", line 163, in maybe_call_get_parameters\n",
      "    return client.get_parameters(get_parameters_ins)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\app.py\", line 283, in _get_parameters\n",
      "    parameters = self.numpy_client.get_parameters(config=ins.config)  # type: ignore\n",
      "TypeError: get_parameters() got an unexpected keyword argument 'config'\n"
     ]
    },
    {
     "ename": "RayTaskError(TypeError)",
     "evalue": "\u001b[36mray::launch_and_get_parameters()\u001b[39m (pid=40416, ip=127.0.0.1)\n  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_client_proxy.py\", line 136, in launch_and_get_parameters\n    return maybe_call_get_parameters(\n  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\client.py\", line 163, in maybe_call_get_parameters\n    return client.get_parameters(get_parameters_ins)\n  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\app.py\", line 283, in _get_parameters\n    parameters = self.numpy_client.get_parameters(config=ins.config)  # type: ignore\nTypeError: get_parameters() got an unexpected keyword argument 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRayTaskError(TypeError)\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\simulation\\app.py:197\u001b[0m, in \u001b[0;36mstart_simulation\u001b[1;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised)\u001b[0m\n\u001b[0;32m    194\u001b[0m     initialized_server\u001b[38;5;241m.\u001b[39mclient_manager()\u001b[38;5;241m.\u001b[39mregister(client\u001b[38;5;241m=\u001b[39mclient_proxy)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43m_fl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m event(EventType\u001b[38;5;241m.\u001b[39mSTART_SIMULATION_LEAVE)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hist\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\server\\app.py:217\u001b[0m, in \u001b[0;36m_fl\u001b[1;34m(server, config)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fl\u001b[39m(\n\u001b[0;32m    213\u001b[0m     server: Server,\n\u001b[0;32m    214\u001b[0m     config: ServerConfig,\n\u001b[0;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m History:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapp_fit: losses_distributed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(hist\u001b[38;5;241m.\u001b[39mlosses_distributed))\n\u001b[0;32m    219\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapp_fit: metrics_distributed_fit \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(hist\u001b[38;5;241m.\u001b[39mmetrics_distributed_fit))\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\server\\server.py:87\u001b[0m, in \u001b[0;36mServer.fit\u001b[1;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Initialize parameters\u001b[39;00m\n\u001b[0;32m     86\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing global parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_initial_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating initial parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     89\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;241m0\u001b[39m, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\server\\server.py:276\u001b[0m, in \u001b[0;36mServer._get_initial_parameters\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    274\u001b[0m random_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_manager\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    275\u001b[0m ins \u001b[38;5;241m=\u001b[39m GetParametersIns(config\u001b[38;5;241m=\u001b[39m{})\n\u001b[1;32m--> 276\u001b[0m get_parameters_res \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived initial parameters from one random client\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_parameters_res\u001b[38;5;241m.\u001b[39mparameters\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_client_proxy.py:73\u001b[0m, in \u001b[0;36mRayClientProxy.get_parameters\u001b[1;34m(self, ins, timeout)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m     72\u001b[0m     log(ERROR, ex)\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m     75\u001b[0m     common\u001b[38;5;241m.\u001b[39mGetParametersRes,\n\u001b[0;32m     76\u001b[0m     res,\n\u001b[0;32m     77\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_client_proxy.py:70\u001b[0m, in \u001b[0;36mRayClientProxy.get_parameters\u001b[1;34m(self, ins, timeout)\u001b[0m\n\u001b[0;32m     66\u001b[0m future_paramseters_res \u001b[38;5;241m=\u001b[39m launch_and_get_parameters\u001b[38;5;241m.\u001b[39moptions(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresources,\n\u001b[0;32m     68\u001b[0m )\u001b[38;5;241m.\u001b[39mremote(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_fn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcid, ins)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture_paramseters_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m     72\u001b[0m     log(ERROR, ex)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     20\u001b[0m     auto_init_ray()\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\worker.py:2667\u001b[0m, in \u001b[0;36mget\u001b[1;34m(object_refs, timeout)\u001b[0m\n\u001b[0;32m   2661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2662\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid type of object refs, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(object_refs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, is given. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject_refs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must either be an ObjectRef or a list of ObjectRefs. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2664\u001b[0m     )\n\u001b[0;32m   2666\u001b[0m \u001b[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[1;32m-> 2667\u001b[0m values, debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2668\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n\u001b[0;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\worker.py:864\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[1;34m(self, object_refs, timeout)\u001b[0m\n\u001b[0;32m    862\u001b[0m     global_worker\u001b[38;5;241m.\u001b[39mcore_worker\u001b[38;5;241m.\u001b[39mdump_object_store_memory_usage()\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayTaskError):\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mas_instanceof_cause()\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[1;31mRayTaskError(TypeError)\u001b[0m: \u001b[36mray::launch_and_get_parameters()\u001b[39m (pid=40416, ip=127.0.0.1)\n  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_client_proxy.py\", line 136, in launch_and_get_parameters\n    return maybe_call_get_parameters(\n  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\client.py\", line 163, in maybe_call_get_parameters\n    return client.get_parameters(get_parameters_ins)\n  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\app.py\", line 283, in _get_parameters\n    parameters = self.numpy_client.get_parameters(config=ins.config)  # type: ignore\nTypeError: get_parameters() got an unexpected keyword argument 'config'"
     ]
    }
   ],
   "source": [
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=5)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        print(f\"Client {self.cid} loss {loss}\")\n",
    "        print(f\"Client {self.cid} accuracy {accuracy}\")\n",
    "        \n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE) #Load Model from here\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZdR1WXDEGxY",
    "outputId": "34c4f998-2ca0-4252-e4f7-424c286a9224"
   },
   "outputs": [],
   "source": [
    "!pip install -q flwr[simulation] torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obhFyleoEM9F",
    "outputId": "99c58edc-bb25-469f-b692-769941f695ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda using PyTorch 1.13.1 and Flower 1.4.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "import time\n",
    "import flwr as fl\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")  # Try \"cuda\" to train on GPU\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 125.4 GB  | Proc size: 304.4 MB\n",
      "GPU RAM Free: 15850MB | Used: 318MB | Util   2% | Total 16376MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    "   process = psutil.Process(os.getpid())\n",
    "   print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "   print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T2L0M1hDEQ54",
    "outputId": "d7c63f7f-13e7-4f97-ff2d-97443878fa29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 10\n",
    "\n",
    "\n",
    "def load_datasets(num_clients: int):\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    partition_size = len(trainset) // num_clients\n",
    "    lengths = [partition_size] * num_clients\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4q9gZPKEEVZ0"
   },
   "outputs": [],
   "source": [
    "from multiprocessing.connection import Client\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):  # Use the passed 'epochs' variable here\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item()  # Make sure to call .item() to get the scalar value\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch}: train loss {epoch_loss:.6f}, accuracy {epoch_acc:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DpDR8IdSEX0E"
   },
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        epochs = config.get(\"epochs\", 1)\n",
    "        start_time = time.time()  # Start time measurement\n",
    "        train(self.net, self.trainloader, epochs)\n",
    "        training_time = time.time() - start_time  # Calculate duration\n",
    "        print(f\"Training time for Client {self.cid}: {training_time:.2f} seconds\")\n",
    "        return get_parameters(self.net), len(self.trainloader), {\"training_time\": training_time}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mSYL7mrZE21l"
   },
   "outputs": [],
   "source": [
    "from typing import Callable, Union\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    MetricsAggregationFn,\n",
    "    NDArrays,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "\n",
    "class FedCustom(fl.server.strategy.Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.client_training_times = {}\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedCustom\"\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        return fl.common.ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    def configure_fit(self, server_round: int, parameters: Parameters, client_manager: ClientManager):\n",
    "        sample_size, min_num_clients = self.num_fit_clients(client_manager.num_available())\n",
    "        clients = client_manager.sample(num_clients=sample_size, min_num_clients=min_num_clients)\n",
    "        epochs_sc = 5\n",
    "        epochs_hl = 4\n",
    "\n",
    "        standard_config = {\"lr\": 0.001, \"epochs\": epochs_sc}\n",
    "        higher_lr_config = {\"lr\": 0.0001, \"epochs\": epochs_hl}\n",
    "        fit_configurations = []\n",
    "\n",
    "        for client in clients:\n",
    "            # Choose config based on the previous training time\n",
    "            last_time = self.client_training_times.get(client.cid, 0)  # Default to 0 if no time recorded\n",
    "            print(f\"This is the last time {last_time}\")\n",
    "\n",
    "            config_to_use = standard_config if last_time < 13.8 else higher_lr_config\n",
    "            fit_configurations.append((client, FitIns(parameters, config_to_use)))\n",
    "\n",
    "        return fit_configurations\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "        for client, fit_res in results:\n",
    "            # Update training times for each client\n",
    "            self.client_training_times[client.cid] = fit_res.metrics.get(\"training_time\", 0)\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "        parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
    "        metrics_aggregated = {}\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate global model parameters using an evalua\n",
    "        tion function.\"\"\"\n",
    "\n",
    "        # Let's assume we won't perform the global model evaluation on the server side.\n",
    "        return None\n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVICE.type == \"cuda\":\n",
    "    # Use a single client to train the global model\n",
    "    client_resources = {\"num_gpus\": .25, \"num_cpus\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvJM3bH4HDth",
    "outputId": "a273cb4a-ef0a-40e3-f789-e8f1f37366ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-06-26 19:27:34,205 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2024-06-26 19:27:38,354\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "INFO flwr 2024-06-26 19:27:40,355 | app.py:180 | Flower VCE: Ray initialized with resources: {'node:127.0.0.1': 1.0, 'object_store_memory': 37484094259.0, 'memory': 77462886605.0, 'GPU': 1.0, 'accelerator_type:RTX': 1.0, 'node:__internal_head__': 1.0, 'CPU': 32.0}\n",
      "INFO flwr 2024-06-26 19:27:40,358 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2024-06-26 19:27:40,366 | server.py:269 | Using initial parameters provided by strategy\n",
      "INFO flwr 2024-06-26 19:27:40,367 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2024-06-26 19:27:40,369 | server.py:101 | FL starting\n",
      "DEBUG flwr 2024-06-26 19:27:40,370 | server.py:218 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "\u001b[36m(launch_and_fit pid=30860)\u001b[0m [Client 4] fit, config: {'lr': 0.001, 'epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=32076)\u001b[0m Epoch 0: train loss 0.064907, accuracy 0.233556\n",
      "\u001b[36m(launch_and_fit pid=17624)\u001b[0m [Client 6] fit, config: {'lr': 0.001, 'epochs': 5}\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=30860)\u001b[0m Epoch 2: train loss 0.051712, accuracy 0.391333\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32076)\u001b[0m Training time for Client 5: 21.60 seconds\n",
      "\u001b[36m(launch_and_fit pid=30860)\u001b[0m Epoch 4: train loss 0.047215, accuracy 0.442667\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=28988)\u001b[0m [Client 8] fit, config: {'lr': 0.001, 'epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=17624)\u001b[0m Training time for Client 6: 21.88 seconds\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=28988)\u001b[0m Epoch 0: train loss 0.064669, accuracy 0.242222\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=22936)\u001b[0m [Client 1] fit, config: {'lr': 0.001, 'epochs': 5}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12124)\u001b[0m Epoch 2: train loss 0.050234, accuracy 0.415111\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=28988)\u001b[0m Training time for Client 8: 22.15 seconds\n",
      "\u001b[36m(launch_and_fit pid=22832)\u001b[0m [Client 0] fit, config: {'lr': 0.001, 'epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=12124)\u001b[0m Epoch 4: train loss 0.045334, accuracy 0.466000\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12124)\u001b[0m Training time for Client 7: 22.19 seconds\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=25520)\u001b[0m [Client 9] fit, config: {'lr': 0.001, 'epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=22832)\u001b[0m Epoch 0: train loss 0.064502, accuracy 0.233111\n",
      "\u001b[36m(launch_and_fit pid=25520)\u001b[0m Epoch 0: train loss 0.065076, accuracy 0.228667\n",
      "\u001b[36m(launch_and_fit pid=25520)\u001b[0m Epoch 2: train loss 0.051910, accuracy 0.388444\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=22832)\u001b[0m Training time for Client 0: 20.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-06-26 19:29:09,753 | server.py:232 | fit_round 1 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-06-26 19:29:09,787 | server.py:168 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=26100)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_fit pid=25520)\u001b[0m Epoch 4: train loss 0.046451, accuracy 0.451111\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=25520)\u001b[0m Training time for Client 9: 20.67 seconds\n",
      "\u001b[36m(launch_and_evaluate pid=16172)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=33496)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=18692)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=21992)\u001b[0m [Client 4] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR flwr 2024-06-26 19:31:42,598 | ray_client_proxy.py:104 | \u001b[36mray::launch_and_evaluate()\u001b[39m (pid=21992, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_client_proxy.py\", line 160, in launch_and_evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\client.py\", line 205, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\app.py\", line 321, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\1810498520.py\", line 25, in evaluate\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\756452527.py\", line 63, in test\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\756452527.py\", line 14, in forward\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m fatal   : Memory allocation failure\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m fatal   : Memory allocation failure\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m *** SIGABRT received at time=1719410502 ***\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FFA28B1DD61  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF996415136  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FFA28B1D492  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF6354C2297  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FFA285CDD31  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FFA2AF4AD6C  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FFA2AF33CC6  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FFA2AF48CDF  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FFA2AED5BEA  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FFA2AED2EF1  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FFA284D2BDC  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF9AC146BA7  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF9964E8B08  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF9964ED947  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF9964F3354  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF9964E8852  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF9964E9E71  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995F96DF3  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995F96D39  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995D9A4EE  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995DED4A5  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995DA06CE  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995E241FD  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995E25D6F  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995E13ADD  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995E218AC  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995DEDF78  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995FA1123  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995F99ACA  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF995F99FD4  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF9964ED49C  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m     @   00007FF9964F1F64  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m Fatal Python error: Aborted\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m \n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m Stack (most recent call first):\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m   File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\worker.py\", line 879 in main_loop\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m   File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\workers\\default_worker.py\", line 282 in <module>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1984, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_client_proxy.py\", line 160, in launch_and_evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\client.py\", line 205, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\app.py\", line 321, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\1810498520.py\", line 25, in evaluate\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\756452527.py\", line 63, in test\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\756452527.py\", line 17, in forward\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2281, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2177, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1832, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1833, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2071, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1089, in ray._raylet.store_task_errors\n",
      "  File \"python\\ray\\_raylet.pyx\", line 4575, in ray._raylet.CoreWorker.store_task_outputs\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\serialization.py\", line 494, in serialize\n",
      "    return self._serialize_to_msgpack(value)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\serialization.py\", line 468, in _serialize_to_msgpack\n",
      "    msgpack_data = MessagePackSerializer.dumps(value, _python_serializer)\n",
      "  File \"python\\ray\\includes/serialization.pxi\", line 175, in ray._raylet.MessagePackSerializer.dumps\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\msgpack\\__init__.py\", line 36, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack\\\\_packer.pyx\", line 120, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m Stack (most recent call first):\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m   File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\worker.py\", line 879 in main_loop\n",
      "\u001b[36m(launch_and_evaluate pid=22336)\u001b[0m   File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\workers\\default_worker.py\", line 282 in <module>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 2896c8822a94d77a320bfbc25a92e52a2a0cbc2701000000 Worker ID: 1726800cfa4272d43d6822356a1f27f44c83334c16f978add39cac6a Node ID: 5e0795a7e98bd965c7dad56b63592a1970a24ce210fd709fe4c53c77 Worker IP address: 127.0.0.1 Worker port: 62375 Worker PID: 22336 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 10054. An existing connection was forcibly closed by the remote host. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m [Client 5] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m fatal   : Memory allocation failure\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m *** SIGABRT received at time=1719410513 ***\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FFA28B1DD61  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF996415136  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FFA28B1D492  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF6354C2297  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FFA285CDD31  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FFA2AF4AD6C  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FFA2AF33CC6  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FFA2AF48CDF  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FFA2AED5BEA  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FFA2AED2EF1  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FFA284D2BDC  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF9AC146BA7  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF9964E8B08  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF9964ED947  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF9964F3354  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF9964E8852  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF9964E9E71  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995F96DF3  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995F96D39  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995D9A4EE  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995DED4A5  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995DA06CE  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995E241FD  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995E25D6F  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995E13ADD  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995E218AC  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995DEDF78  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995FA1123  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995F99ACA  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF995F99FD4  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF9964ED49C  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m     @   00007FF9964F1F64  (unknown)  (unknown)\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m Fatal Python error: Aborted\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m \n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m Stack (most recent call first):\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m   File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\worker.py\", line 879 in main_loop\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m   File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\workers\\default_worker.py\", line 282 in <module>\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m Stack (most recent call first):\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m   File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\worker.py\", line 879 in main_loop\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m   File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\workers\\default_worker.py\", line 282 in <module>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1984, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_client_proxy.py\", line 160, in launch_and_evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\client.py\", line 205, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\app.py\", line 321, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\1810498520.py\", line 25, in evaluate\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\756452527.py\", line 63, in test\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\756452527.py\", line 17, in forward\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2281, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2177, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1832, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1833, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2071, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1089, in ray._raylet.store_task_errors\n",
      "  File \"python\\ray\\_raylet.pyx\", line 4575, in ray._raylet.CoreWorker.store_task_outputs\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\serialization.py\", line 494, in serialize\n",
      "    return self._serialize_to_msgpack(value)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\serialization.py\", line 468, in _serialize_to_msgpack\n",
      "    msgpack_data = MessagePackSerializer.dumps(value, _python_serializer)\n",
      "  File \"python\\ray\\includes/serialization.pxi\", line 175, in ray._raylet.MessagePackSerializer.dumps\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\msgpack\\__init__.py\", line 36, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack\\\\_packer.pyx\", line 120, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 60a1add8594bee923ea31a90604f6011ba95bee701000000 Worker ID: 291f809000bf94a8e7a37719f3befec6ce477f33598582079050b810 Node ID: 5e0795a7e98bd965c7dad56b63592a1970a24ce210fd709fe4c53c77 Worker IP address: 127.0.0.1 Worker port: 62462 Worker PID: 28288 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 10054. An existing connection was forcibly closed by the remote host. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1984, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_client_proxy.py\", line 160, in launch_and_evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\client.py\", line 205, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\app.py\", line 321, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\1810498520.py\", line 25, in evaluate\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\756452527.py\", line 63, in test\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\756452527.py\", line 17, in forward\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2281, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2177, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1832, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1833, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2071, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1089, in ray._raylet.store_task_errors\n",
      "  File \"python\\ray\\_raylet.pyx\", line 4575, in ray._raylet.CoreWorker.store_task_outputs\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\serialization.py\", line 494, in serialize\n",
      "    return self._serialize_to_msgpack(value)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\serialization.py\", line 468, in _serialize_to_msgpack\n",
      "    msgpack_data = MessagePackSerializer.dumps(value, _python_serializer)\n",
      "  File \"python\\ray\\includes/serialization.pxi\", line 175, in ray._raylet.MessagePackSerializer.dumps\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\msgpack\\__init__.py\", line 36, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack\\\\_packer.pyx\", line 120, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF996415136  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF6354C2297  (unknown)  OPENSSL_Applink\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FFA2AF4AD6C  (unknown)  memset\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FFA2AF33CC6  (unknown)  _C_specific_handler\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FFA2AF48CDF  (unknown)  _chkstk\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FFA2AED5BEA  (unknown)  RtlRestoreContext\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FFA2AED2EF1  (unknown)  RtlRaiseException\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF9964E8B08  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF9964ED947  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF9964F3354  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF9964E8852  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF9964E9E71  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995F96DF3  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995F96D39  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995D9A4EE  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995DED4A5  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995DA06CE  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995E241FD  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995E25D6F  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995E13ADD  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995E218AC  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995DEDF78  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995FA1123  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995F99ACA  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF995F99FD4  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF9964ED49C  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF9964F1F32  (unknown)  PyInit__raylet\n",
      "\u001b[36m(launch_and_evaluate pid=28288)\u001b[0m fatal   : Memory allocation failure\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m *** SIGABRT received at time=1719410524 ***\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m     @   00007FF9AC146BA7  (unknown)  (unknown)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m Fatal Python error: Aborted\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m \n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m Stack (most recent call first):\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m   File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\worker.py\", line 879 in main_loop\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m   File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\workers\\default_worker.py\", line 282 in <module>\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m Stack (most recent call first):\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m   File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\worker.py\", line 879 in main_loop\n",
      "\u001b[36m(launch_and_evaluate pid=8224)\u001b[0m   File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\workers\\default_worker.py\", line 282 in <module>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 1562fa3f988b548fdc2ff62a83689557accf538001000000 Worker ID: a24a6812863c9e5ef55244ea6530cda19871f7441b8c9fd5be98077d Node ID: 5e0795a7e98bd965c7dad56b63592a1970a24ce210fd709fe4c53c77 Worker IP address: 127.0.0.1 Worker port: 62475 Worker PID: 8224 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 10054. An existing connection was forcibly closed by the remote host. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "\u001b[36m(launch_and_evaluate pid=33320)\u001b[0m [Client 5] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR flwr 2024-06-26 19:32:15,803 | ray_client_proxy.py:104 | The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "DEBUG flwr 2024-06-26 19:32:15,812 | server.py:182 | evaluate_round 1 received 8 results and 2 failures\n",
      "DEBUG flwr 2024-06-26 19:32:15,814 | server.py:218 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(launch_and_evaluate pid=33320)\u001b[0m fatal   : Memory allocation failure\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-06-26 19:32:15,847 | server.py:232 | fit_round 2 received 0 results and 10 failures\n",
      "DEBUG flwr 2024-06-26 19:32:15,849 | server.py:168 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flwr 2024-06-26 19:32:15,879 | server.py:182 | evaluate_round 2 received 0 results and 10 failures\n",
      "DEBUG flwr 2024-06-26 19:32:15,882 | server.py:218 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flwr 2024-06-26 19:32:15,919 | server.py:232 | fit_round 3 received 0 results and 10 failures\n",
      "DEBUG flwr 2024-06-26 19:32:15,921 | server.py:168 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flwr 2024-06-26 19:32:15,956 | server.py:182 | evaluate_round 3 received 0 results and 10 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1984, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_client_proxy.py\", line 160, in launch_and_evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\client.py\", line 205, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\app.py\", line 321, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\1810498520.py\", line 25, in evaluate\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\756452527.py\", line 63, in test\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\756452527.py\", line 17, in forward\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2281, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2177, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1832, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1833, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2071, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1089, in ray._raylet.store_task_errors\n",
      "  File \"python\\ray\\_raylet.pyx\", line 4575, in ray._raylet.CoreWorker.store_task_outputs\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\serialization.py\", line 494, in serialize\n",
      "    return self._serialize_to_msgpack(value)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\serialization.py\", line 478, in _serialize_to_msgpack\n",
      "    return MessagePackSerializedObject(\n",
      "  File \"python\\ray\\includes/serialization.pxi\", line 471, in ray._raylet.MessagePackSerializedObject.__init__\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\msgpack\\__init__.py\", line 36, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack\\\\_packer.pyx\", line 120, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 207442655e72afef182d4383439be2c28c7504de01000000 Worker ID: a117c3b43418387ddf1c91cfbce39d5fd9b0fdaa438801bc5f25d210 Node ID: 5e0795a7e98bd965c7dad56b63592a1970a24ce210fd709fe4c53c77 Worker IP address: 127.0.0.1 Worker port: 62483 Worker PID: 33320 Worker exit type: SYSTEM_ERROR Worker exit detail: The leased worker has unrecoverable failure. Worker is requested to be destroyed when it is returned. Worker exits with an exit code None. Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1984, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_client_proxy.py\", line 160, in launch_and_evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\client.py\", line 205, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\flwr\\client\\app.py\", line 321, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\1810498520.py\", line 25, in evaluate\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\756452527.py\", line 63, in test\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26896\\756452527.py\", line 17, in forward\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2281, in ray._raylet.task_execution_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2177, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1832, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1833, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 2071, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1089, in ray._raylet.store_task_errors\n",
      "  File \"python\\ray\\_raylet.pyx\", line 4575, in ray._raylet.CoreWorker.store_task_outputs\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\serialization.py\", line 494, in serialize\n",
      "    return self._serialize_to_msgpack(value)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\serialization.py\", line 478, in _serialize_to_msgpack\n",
      "    return MessagePackSerializedObject(\n",
      "  File \"python\\ray\\includes/serialization.pxi\", line 471, in ray._raylet.MessagePackSerializedObject.__init__\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\msgpack\\__init__.py\", line 36, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack\\\\_packer.pyx\", line 120, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "This is the last time 21.595441579818726\n",
      "This is the last time 22.129435300827026\n",
      "This is the last time 21.85044026374817\n",
      "This is the last time 20.317894220352173\n",
      "This is the last time 22.151278257369995\n",
      "This is the last time 21.87843942642212\n",
      "This is the last time 22.18725085258484\n",
      "This is the last time 22.14625382423401\n",
      "This is the last time 20.671897172927856\n",
      "This is the last time 22.017260313034058\n",
      "This is the last time 21.87843942642212\n",
      "This is the last time 21.595441579818726\n",
      "This is the last time 22.151278257369995\n",
      "This is the last time 22.017260313034058\n",
      "This is the last time 20.671897172927856\n",
      "This is the last time 20.317894220352173\n",
      "This is the last time 21.85044026374817\n",
      "This is the last time 22.129435300827026\n",
      "This is the last time 22.18725085258484\n",
      "This is the last time 22.14625382423401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-06-26 19:32:15,958 | server.py:147 | FL finished in 275.5888034\n",
      "INFO flwr 2024-06-26 19:32:15,962 | app.py:218 | app_fit: losses_distributed [(1, 0.0568882015645504)]\n",
      "INFO flwr 2024-06-26 19:32:15,965 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2024-06-26 19:32:15,969 | app.py:220 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2024-06-26 19:32:15,971 | app.py:221 | app_fit: losses_centralized []\n",
      "INFO flwr 2024-06-26 19:32:15,975 | app.py:222 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.0568882015645504"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    strategy=FedCustom(),  # <-- pass the new strategy here\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=5)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        print(f\"Client {self.cid} loss {loss}\")\n",
    "        print(f\"Client {self.cid} accuracy {accuracy}\")\n",
    "        \n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE) #Load Model from here\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZdR1WXDEGxY",
    "outputId": "34c4f998-2ca0-4252-e4f7-424c286a9224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q flwr[simulation] torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obhFyleoEM9F",
    "outputId": "99c58edc-bb25-469f-b692-769941f695ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda using PyTorch 1.13.1 and Flower 1.4.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "import time\n",
    "import flwr as fl\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")  # Try \"cuda\" to train on GPU\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 125.7 GB  | Proc size: 303.6 MB\n",
      "GPU RAM Free: 15758MB | Used: 410MB | Util   3% | Total 16376MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    "   process = psutil.Process(os.getpid())\n",
    "   print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "   print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T2L0M1hDEQ54",
    "outputId": "d7c63f7f-13e7-4f97-ff2d-97443878fa29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 10\n",
    "\n",
    "\n",
    "def load_datasets(num_clients: int):\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    partition_size = len(trainset) // num_clients\n",
    "    lengths = [partition_size] * num_clients\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4q9gZPKEEVZ0"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):  # Use the passed 'epochs' variable here\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item()  # Make sure to call .item() to get the scalar value\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch}: train loss {epoch_loss:.6f}, accuracy {epoch_acc:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DpDR8IdSEX0E"
   },
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        epochs = config.get(\"epochs\", 1)\n",
    "        start_time = time.time()  # Start time measurement\n",
    "        train(self.net, self.trainloader, epochs)\n",
    "        training_time = time.time() - start_time  # Calculate duration\n",
    "        print(f\"Training time for Client {self.cid}: {training_time:.2f} seconds\")\n",
    "        return get_parameters(self.net), len(self.trainloader), {\"training_time\": training_time}\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mSYL7mrZE21l"
   },
   "outputs": [],
   "source": [
    "from typing import Callable, Union\n",
    "\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    MetricsAggregationFn,\n",
    "    NDArrays,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "\n",
    "\n",
    "class FedCustom(fl.server.strategy.Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fraction_fit: float = 1.0,\n",
    "        fraction_evaluate: float = 1.0,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_evaluate_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.client_training_times = {}\n",
    "    def __repr__(self) -> str:\n",
    "        return \"FedCustom\"\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        net = Net()\n",
    "        ndarrays = get_parameters(net)\n",
    "        return fl.common.ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    def configure_fit(self, server_round: int, parameters: Parameters, client_manager: ClientManager):\n",
    "        sample_size, min_num_clients = self.num_fit_clients(client_manager.num_available())\n",
    "        clients = client_manager.sample(num_clients=sample_size, min_num_clients=min_num_clients)\n",
    "        epochs_sc = 5\n",
    "        epochs_hl = 3\n",
    "\n",
    "        standard_config = {\"lr\": 0.001, \"epochs\": epochs_sc}\n",
    "        higher_lr_config = {\"lr\": 0.0001, \"epochs\": epochs_hl}\n",
    "        fit_configurations = []\n",
    "\n",
    "        for client in clients:\n",
    "            # Choose config based on the previous training time\n",
    "            last_time = self.client_training_times.get(client.cid, 0)  # Default to 0 if no time recorded\n",
    "            print(f\"This is the last time {last_time}\")\n",
    "            \n",
    "\n",
    "\n",
    "            config_to_use = standard_config if last_time < 13.8 else higher_lr_config\n",
    "            fit_configurations.append((client, FitIns(parameters, config_to_use)))\n",
    "\n",
    "        return fit_configurations\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "        for client, fit_res in results:\n",
    "            # Update training times for each client\n",
    "            self.client_training_times[client.cid] = fit_res.metrics.get(\"training_time\", 0)\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "        parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
    "        metrics_aggregated = {}\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "        config = {}\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "        metrics_aggregated = {}\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate global model parameters using an evalua\n",
    "        tion function.\"\"\"\n",
    "\n",
    "        # Let's assume we won't perform the global model evaluation on the server side.\n",
    "        return None\n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVICE.type == \"cuda\":\n",
    "    # Use a single client to train the global model\n",
    "    client_resources = {\"num_gpus\": .25, \"num_cpus\": 2} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvJM3bH4HDth",
    "outputId": "a273cb4a-ef0a-40e3-f789-e8f1f37366ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-06-27 13:44:10,502 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2024-06-27 13:44:14,913\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "INFO flwr 2024-06-27 13:44:16,893 | app.py:180 | Flower VCE: Ray initialized with resources: {'accelerator_type:RTX': 1.0, 'GPU': 1.0, 'node:__internal_head__': 1.0, 'memory': 77620241408.0, 'object_store_memory': 37551532032.0, 'node:127.0.0.1': 1.0, 'CPU': 32.0}\n",
      "INFO flwr 2024-06-27 13:44:16,895 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2024-06-27 13:44:16,902 | server.py:269 | Using initial parameters provided by strategy\n",
      "INFO flwr 2024-06-27 13:44:16,904 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2024-06-27 13:44:16,905 | server.py:101 | FL starting\n",
      "DEBUG flwr 2024-06-27 13:44:16,906 | server.py:218 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "This is the last time 0\n",
      "\u001b[36m(launch_and_fit pid=21420)\u001b[0m [Client 5] fit, config: {'lr': 0.001, 'epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=10780)\u001b[0m Epoch 0: train loss 0.064418, accuracy 0.233778\n",
      "\u001b[36m(launch_and_fit pid=43732)\u001b[0m [Client 7] fit, config: {'lr': 0.001, 'epochs': 5}\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=42984)\u001b[0m Epoch 2: train loss 0.051134, accuracy 0.396667\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=10780)\u001b[0m Training time for Client 1: 21.21 seconds\n",
      "\u001b[36m(launch_and_fit pid=43732)\u001b[0m Epoch 4: train loss 0.045833, accuracy 0.472444\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=7400)\u001b[0m [Client 8] fit, config: {'lr': 0.001, 'epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=21420)\u001b[0m Training time for Client 5: 23.45 seconds\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=21420)\u001b[0m Epoch 4: train loss 0.046396, accuracy 0.453778\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=25352)\u001b[0m [Client 4] fit, config: {'lr': 0.001, 'epochs': 5}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=7400)\u001b[0m Epoch 0: train loss 0.064977, accuracy 0.238222\n",
      "\u001b[36m(launch_and_fit pid=33924)\u001b[0m Epoch 0: train loss 0.065122, accuracy 0.227111\n",
      "\u001b[36m(launch_and_fit pid=2296)\u001b[0m Epoch 2: train loss 0.052044, accuracy 0.390000\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=7400)\u001b[0m Training time for Client 8: 22.94 seconds\n",
      "\u001b[36m(launch_and_fit pid=2296)\u001b[0m Epoch 4: train loss 0.047565, accuracy 0.436889\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=6040)\u001b[0m [Client 6] fit, config: {'lr': 0.001, 'epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=25352)\u001b[0m Training time for Client 4: 22.80 seconds\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=27796)\u001b[0m Epoch 0: train loss 0.065789, accuracy 0.216889\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=27796)\u001b[0m [Client 3] fit, config: {'lr': 0.001, 'epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=27796)\u001b[0m Epoch 2: train loss 0.052146, accuracy 0.393778\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-06-27 13:45:46,823 | server.py:232 | fit_round 1 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-06-27 13:45:46,880 | server.py:168 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6040)\u001b[0m Training time for Client 6: 20.80 seconds\n",
      "\u001b[36m(launch_and_fit pid=6040)\u001b[0m Epoch 4: train loss 0.047430, accuracy 0.435333\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=31824)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_fit pid=27796)\u001b[0m Training time for Client 3: 20.71 seconds\n",
      "\u001b[36m(launch_and_fit pid=27796)\u001b[0m Epoch 4: train loss 0.047805, accuracy 0.432000\n",
      "\u001b[36m(launch_and_evaluate pid=42988)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=7044)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=24988)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=41232)\u001b[0m [Client 1] evaluate, config: {}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    strategy=FedCustom(),  # <-- pass the new strategy here\n",
    "    client_resources=client_resources,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=5)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        print(f\"Client {self.cid} loss {loss}\")\n",
    "        print(f\"Client {self.cid} accuracy {accuracy}\")\n",
    "        \n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE) #Load Model from here\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-05-29 11:36:33,564 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-05-29 11:36:40,084 | app.py:180 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'CPU': 32.0, 'memory': 61953181082.0, 'object_store_memory': 30837077606.0, 'node:127.0.0.1': 1.0}\n",
      "INFO flwr 2024-05-29 11:36:40,087 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2024-05-29 11:36:40,089 | server.py:273 | Requesting initial parameters from one random client\n",
      "INFO flwr 2024-05-29 11:36:44,026 | server.py:277 | Received initial parameters from one random client\n",
      "INFO flwr 2024-05-29 11:36:44,027 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2024-05-29 11:36:44,029 | server.py:101 | FL starting\n",
      "DEBUG flwr 2024-05-29 11:36:44,031 | server.py:218 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pid=27924)\u001b[0m [Client 3] get_parameters\n",
      " pid=27924)\u001b[0m [Client 8] fit, config: {}\n",
      " pid=27000)\u001b[0m [Client 9] fit, config: {}\n",
      " pid=26956)\u001b[0m [Client 5] fit, config: {}\n",
      " pid=19244)\u001b[0m [Client 3] fit, config: {}\n",
      " pid=27924)\u001b[0m Epoch 0: train loss 0.064283, accuracy 0.244000\n",
      " pid=27924)\u001b[0m Epoch 1: train loss 0.056345, accuracy 0.335556\n",
      " pid=27924)\u001b[0m Epoch 2: train loss 0.052596, accuracy 0.383111\n",
      " pid=27000)\u001b[0m Epoch 0: train loss 0.065390, accuracy 0.219333\n",
      " pid=26956)\u001b[0m Epoch 0: train loss 0.065386, accuracy 0.222667\n",
      " pid=27924)\u001b[0m Epoch 3: train loss 0.049705, accuracy 0.431111\n",
      " pid=19244)\u001b[0m Epoch 0: train loss 0.064883, accuracy 0.228667\n",
      " pid=27000)\u001b[0m Epoch 1: train loss 0.057237, accuracy 0.326667\n",
      " pid=26956)\u001b[0m Epoch 1: train loss 0.057874, accuracy 0.322444\n",
      " pid=27924)\u001b[0m Epoch 4: train loss 0.047198, accuracy 0.454667\n",
      " pid=27924)\u001b[0m [Client 1] fit, config: {}\n",
      " pid=19244)\u001b[0m Epoch 1: train loss 0.056371, accuracy 0.348444\n",
      " pid=27000)\u001b[0m Epoch 2: train loss 0.053247, accuracy 0.374667\n",
      " pid=26956)\u001b[0m Epoch 2: train loss 0.054083, accuracy 0.371333\n",
      " pid=27924)\u001b[0m Epoch 0: train loss 0.065366, accuracy 0.229556\n",
      " pid=19244)\u001b[0m Epoch 2: train loss 0.052883, accuracy 0.388889\n",
      " pid=27000)\u001b[0m Epoch 3: train loss 0.050352, accuracy 0.408222\n",
      " pid=26956)\u001b[0m Epoch 3: train loss 0.051255, accuracy 0.404000\n",
      " pid=27924)\u001b[0m Epoch 1: train loss 0.055373, accuracy 0.356444\n",
      " pid=19244)\u001b[0m Epoch 3: train loss 0.050108, accuracy 0.422000\n",
      " pid=27000)\u001b[0m Epoch 4: train loss 0.048146, accuracy 0.439778\n",
      " pid=26956)\u001b[0m Epoch 4: train loss 0.048693, accuracy 0.438000\n",
      " pid=27000)\u001b[0m [Client 0] fit, config: {}\n",
      " pid=26956)\u001b[0m [Client 7] fit, config: {}\n",
      " pid=27924)\u001b[0m Epoch 2: train loss 0.051266, accuracy 0.410000\n",
      " pid=19244)\u001b[0m Epoch 4: train loss 0.047495, accuracy 0.445333\n",
      " pid=19244)\u001b[0m [Client 2] fit, config: {}\n",
      " pid=27000)\u001b[0m Epoch 0: train loss 0.064989, accuracy 0.228000\n",
      " pid=26956)\u001b[0m Epoch 0: train loss 0.064233, accuracy 0.237333\n",
      " pid=27924)\u001b[0m Epoch 3: train loss 0.048039, accuracy 0.435111\n",
      " pid=19244)\u001b[0m Epoch 0: train loss 0.064962, accuracy 0.224667\n",
      " pid=27000)\u001b[0m Epoch 1: train loss 0.056978, accuracy 0.330667\n",
      " pid=26956)\u001b[0m Epoch 1: train loss 0.056086, accuracy 0.346667\n",
      " pid=27924)\u001b[0m Epoch 4: train loss 0.045961, accuracy 0.471111\n",
      " pid=27924)\u001b[0m [Client 4] fit, config: {}\n",
      " pid=19244)\u001b[0m Epoch 1: train loss 0.057172, accuracy 0.331333\n",
      " pid=27000)\u001b[0m Epoch 2: train loss 0.052656, accuracy 0.386444\n",
      " pid=26956)\u001b[0m Epoch 2: train loss 0.052179, accuracy 0.392444\n",
      " pid=27924)\u001b[0m Epoch 0: train loss 0.064859, accuracy 0.233778\n",
      " pid=19244)\u001b[0m Epoch 2: train loss 0.052711, accuracy 0.378889\n",
      " pid=27000)\u001b[0m Epoch 3: train loss 0.049592, accuracy 0.423778\n",
      " pid=26956)\u001b[0m Epoch 3: train loss 0.049415, accuracy 0.424444\n",
      " pid=27924)\u001b[0m Epoch 1: train loss 0.056354, accuracy 0.343333\n",
      " pid=19244)\u001b[0m Epoch 3: train loss 0.049872, accuracy 0.417778\n",
      " pid=27000)\u001b[0m Epoch 4: train loss 0.047783, accuracy 0.446667\n",
      " pid=26956)\u001b[0m Epoch 4: train loss 0.047490, accuracy 0.450444\n",
      " pid=27000)\u001b[0m [Client 6] fit, config: {}\n",
      " pid=27924)\u001b[0m Epoch 2: train loss 0.052208, accuracy 0.391333\n",
      " pid=19244)\u001b[0m Epoch 4: train loss 0.048091, accuracy 0.434222\n",
      " pid=27000)\u001b[0m Epoch 0: train loss 0.065154, accuracy 0.239333\n",
      " pid=27924)\u001b[0m Epoch 3: train loss 0.049021, accuracy 0.424222\n",
      " pid=27000)\u001b[0m Epoch 1: train loss 0.056829, accuracy 0.333556\n",
      " pid=27924)\u001b[0m Epoch 4: train loss 0.046805, accuracy 0.464889\n",
      " pid=27000)\u001b[0m Epoch 2: train loss 0.053426, accuracy 0.377778\n",
      " pid=27000)\u001b[0m Epoch 3: train loss 0.050676, accuracy 0.410444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-05-29 11:37:45,189 | server.py:232 | fit_round 1 received 10 results and 0 failures\n",
      "WARNING flwr 2024-05-29 11:37:45,233 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2024-05-29 11:37:45,235 | server.py:168 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pid=27000)\u001b[0m Epoch 4: train loss 0.048110, accuracy 0.436444\n",
      " pid=27000)\u001b[0m [Client 4] evaluate, config: {}\n",
      " pid=27000)\u001b[0m Client 4 loss 0.057416656255722044\n",
      " pid=27000)\u001b[0m Client 4 accuracy 0.348\n",
      " pid=27924)\u001b[0m [Client 8] evaluate, config: {}\n",
      " pid=27924)\u001b[0m Client 8 loss 0.05749241328239441\n",
      " pid=27924)\u001b[0m Client 8 accuracy 0.394\n",
      " pid=27924)\u001b[0m [Client 6] evaluate, config: {}\n",
      " pid=27000)\u001b[0m [Client 2] evaluate, config: {}\n",
      " pid=27924)\u001b[0m Client 6 loss 0.05749799847602844\n",
      " pid=27924)\u001b[0m Client 6 accuracy 0.348\n",
      " pid=27000)\u001b[0m Client 2 loss 0.058668370962142946\n",
      " pid=27000)\u001b[0m Client 2 accuracy 0.342\n",
      " pid=27000)\u001b[0m [Client 9] evaluate, config: {}\n",
      " pid=27000)\u001b[0m Client 9 loss 0.05861459255218506\n",
      " pid=27000)\u001b[0m Client 9 accuracy 0.36\n",
      " pid=27000)\u001b[0m [Client 1] evaluate, config: {}\n",
      " pid=27000)\u001b[0m Client 1 loss 0.057283300876617434\n",
      " pid=27000)\u001b[0m Client 1 accuracy 0.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-05-29 11:38:00,139 | server.py:182 | evaluate_round 1 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pid=27924)\u001b[0m [Client 5] evaluate, config: {}\n",
      " pid=27000)\u001b[0m [Client 0] evaluate, config: {}\n",
      " pid=26956)\u001b[0m [Client 7] evaluate, config: {}\n",
      " pid=19244)\u001b[0m [Client 3] evaluate, config: {}\n",
      " pid=27924)\u001b[0m Client 5 loss 0.05579921221733093\n",
      " pid=27924)\u001b[0m Client 5 accuracy 0.41\n",
      " pid=27000)\u001b[0m Client 0 loss 0.05796573948860168\n",
      " pid=27000)\u001b[0m Client 0 accuracy 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING flwr 2024-05-29 11:38:00,142 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2024-05-29 11:38:00,144 | server.py:218 | fit_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pid=26956)\u001b[0m Client 7 loss 0.057370660543441775\n",
      " pid=26956)\u001b[0m Client 7 accuracy 0.362\n",
      " pid=19244)\u001b[0m Client 3 loss 0.057644266366958616\n",
      " pid=19244)\u001b[0m Client 3 accuracy 0.364\n",
      " pid=19244)\u001b[0m [Client 8] fit, config: {}\n",
      " pid=26956)\u001b[0m [Client 9] fit, config: {}\n",
      " pid=19244)\u001b[0m Epoch 0: train loss 0.050530, accuracy 0.418222\n",
      " pid=26956)\u001b[0m Epoch 0: train loss 0.051527, accuracy 0.400000\n",
      " pid=19244)\u001b[0m Epoch 1: train loss 0.046498, accuracy 0.465778\n",
      " pid=27924)\u001b[0m [Client 7] fit, config: {}\n",
      " pid=26956)\u001b[0m Epoch 1: train loss 0.047991, accuracy 0.431556\n",
      " pid=27000)\u001b[0m [Client 2] fit, config: {}\n",
      " pid=19244)\u001b[0m Epoch 2: train loss 0.044626, accuracy 0.484889\n",
      " pid=27924)\u001b[0m Epoch 0: train loss 0.050340, accuracy 0.412667\n",
      " pid=26956)\u001b[0m Epoch 2: train loss 0.045316, accuracy 0.465556\n",
      " pid=27000)\u001b[0m Epoch 0: train loss 0.051500, accuracy 0.403111\n",
      " pid=19244)\u001b[0m Epoch 3: train loss 0.042625, accuracy 0.503778\n",
      " pid=27924)\u001b[0m Epoch 1: train loss 0.047050, accuracy 0.448222\n",
      " pid=26956)\u001b[0m Epoch 3: train loss 0.043097, accuracy 0.494667\n",
      " pid=27000)\u001b[0m Epoch 1: train loss 0.047906, accuracy 0.440000\n",
      " pid=19244)\u001b[0m Epoch 4: train loss 0.040469, accuracy 0.528444\n",
      " pid=19244)\u001b[0m [Client 4] fit, config: {}\n",
      " pid=27924)\u001b[0m Epoch 2: train loss 0.044768, accuracy 0.476000\n",
      " pid=26956)\u001b[0m Epoch 4: train loss 0.040796, accuracy 0.526444\n",
      " pid=26956)\u001b[0m [Client 0] fit, config: {}\n",
      " pid=27000)\u001b[0m Epoch 2: train loss 0.045568, accuracy 0.465778\n",
      " pid=19244)\u001b[0m Epoch 0: train loss 0.050550, accuracy 0.407111\n",
      " pid=27924)\u001b[0m Epoch 3: train loss 0.042242, accuracy 0.513333\n",
      " pid=26956)\u001b[0m Epoch 0: train loss 0.051160, accuracy 0.404667\n",
      " pid=27000)\u001b[0m Epoch 3: train loss 0.043297, accuracy 0.500222\n",
      " pid=19244)\u001b[0m Epoch 1: train loss 0.047062, accuracy 0.453333\n",
      " pid=27924)\u001b[0m Epoch 4: train loss 0.040292, accuracy 0.531778\n",
      " pid=27924)\u001b[0m [Client 1] fit, config: {}\n",
      " pid=26956)\u001b[0m Epoch 1: train loss 0.047471, accuracy 0.444444\n",
      " pid=27000)\u001b[0m Epoch 4: train loss 0.041428, accuracy 0.520889\n",
      " pid=27000)\u001b[0m [Client 6] fit, config: {}\n",
      " pid=19244)\u001b[0m Epoch 2: train loss 0.044409, accuracy 0.482889\n",
      " pid=27924)\u001b[0m Epoch 0: train loss 0.050552, accuracy 0.414222\n",
      " pid=26956)\u001b[0m Epoch 2: train loss 0.045068, accuracy 0.472889\n",
      " pid=27000)\u001b[0m Epoch 0: train loss 0.051794, accuracy 0.393111\n",
      " pid=19244)\u001b[0m Epoch 3: train loss 0.042391, accuracy 0.507556\n",
      " pid=27924)\u001b[0m Epoch 1: train loss 0.047419, accuracy 0.453556\n",
      " pid=26956)\u001b[0m Epoch 3: train loss 0.043068, accuracy 0.504222\n",
      " pid=27000)\u001b[0m Epoch 1: train loss 0.048650, accuracy 0.435778\n",
      " pid=19244)\u001b[0m Epoch 4: train loss 0.040546, accuracy 0.535111\n",
      " pid=19244)\u001b[0m [Client 3] fit, config: {}\n",
      " pid=27924)\u001b[0m Epoch 2: train loss 0.044948, accuracy 0.482000\n",
      " pid=26956)\u001b[0m Epoch 4: train loss 0.040577, accuracy 0.525778\n",
      " pid=26956)\u001b[0m [Client 5] fit, config: {}\n",
      " pid=27000)\u001b[0m Epoch 2: train loss 0.045532, accuracy 0.467778\n",
      " pid=19244)\u001b[0m Epoch 0: train loss 0.051494, accuracy 0.402444\n",
      " pid=27924)\u001b[0m Epoch 3: train loss 0.042631, accuracy 0.497556\n",
      " pid=26956)\u001b[0m Epoch 0: train loss 0.051428, accuracy 0.400000\n",
      " pid=27000)\u001b[0m Epoch 3: train loss 0.043566, accuracy 0.486889\n",
      " pid=19244)\u001b[0m Epoch 1: train loss 0.048357, accuracy 0.435111\n",
      " pid=27924)\u001b[0m Epoch 4: train loss 0.040580, accuracy 0.531333\n",
      " pid=26956)\u001b[0m Epoch 1: train loss 0.048156, accuracy 0.438222\n",
      " pid=27000)\u001b[0m Epoch 4: train loss 0.041662, accuracy 0.513778\n",
      " pid=19244)\u001b[0m Epoch 2: train loss 0.046118, accuracy 0.472444\n",
      " pid=26956)\u001b[0m Epoch 2: train loss 0.046218, accuracy 0.464889\n",
      " pid=19244)\u001b[0m Epoch 3: train loss 0.044190, accuracy 0.493111\n",
      " pid=26956)\u001b[0m Epoch 3: train loss 0.043656, accuracy 0.493556\n",
      " pid=19244)\u001b[0m Epoch 4: train loss 0.042199, accuracy 0.518000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-05-29 11:38:43,789 | server.py:232 | fit_round 2 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-05-29 11:38:43,823 | server.py:168 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pid=26956)\u001b[0m Epoch 4: train loss 0.041652, accuracy 0.512444\n",
      " pid=26956)\u001b[0m [Client 0] evaluate, config: {}\n",
      " pid=26956)\u001b[0m Client 0 loss 0.046705979347229004\n",
      " pid=26956)\u001b[0m Client 0 accuracy 0.474\n",
      " pid=26956)\u001b[0m [Client 7] evaluate, config: {}\n",
      " pid=26956)\u001b[0m Client 7 loss 0.04484793257713318\n",
      " pid=26956)\u001b[0m Client 7 accuracy 0.48\n",
      " pid=26956)\u001b[0m [Client 1] evaluate, config: {}\n",
      " pid=19244)\u001b[0m [Client 2] evaluate, config: {}\n",
      " pid=27924)\u001b[0m [Client 3] evaluate, config: {}\n",
      " pid=27000)\u001b[0m [Client 5] evaluate, config: {}\n",
      " pid=26956)\u001b[0m Client 1 loss 0.0451300802230835\n",
      " pid=26956)\u001b[0m Client 1 accuracy 0.474\n",
      " pid=27000)\u001b[0m Client 5 loss 0.043583230257034304\n",
      " pid=27000)\u001b[0m Client 5 accuracy 0.508\n",
      " pid=26956)\u001b[0m [Client 6] evaluate, config: {}\n",
      " pid=19244)\u001b[0m Client 2 loss 0.048428908586502076\n",
      " pid=19244)\u001b[0m Client 2 accuracy 0.438\n",
      " pid=27924)\u001b[0m Client 3 loss 0.04525577282905579\n",
      " pid=27924)\u001b[0m Client 3 accuracy 0.48\n",
      " pid=27000)\u001b[0m [Client 8] evaluate, config: {}\n",
      " pid=19244)\u001b[0m [Client 4] evaluate, config: {}\n",
      " pid=27924)\u001b[0m [Client 9] evaluate, config: {}\n",
      " pid=26956)\u001b[0m Client 6 loss 0.04551054120063782\n",
      " pid=26956)\u001b[0m Client 6 accuracy 0.492\n",
      " pid=27000)\u001b[0m Client 8 loss 0.044020456314086916\n",
      " pid=27000)\u001b[0m Client 8 accuracy 0.486\n",
      " pid=19244)\u001b[0m Client 4 loss 0.04514945816993714\n",
      " pid=19244)\u001b[0m Client 4 accuracy 0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-05-29 11:38:58,868 | server.py:182 | evaluate_round 2 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-05-29 11:38:58,870 | server.py:218 | fit_round 3: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pid=27924)\u001b[0m Client 9 loss 0.04738649296760559\n",
      " pid=27924)\u001b[0m Client 9 accuracy 0.486\n",
      " pid=27924)\u001b[0m [Client 7] fit, config: {}\n",
      " pid=27924)\u001b[0m Epoch 0: train loss 0.044175, accuracy 0.496000\n",
      " pid=27000)\u001b[0m [Client 9] fit, config: {}\n",
      " pid=19244)\u001b[0m [Client 4] fit, config: {}\n",
      " pid=27924)\u001b[0m Epoch 1: train loss 0.041426, accuracy 0.526000\n",
      " pid=27000)\u001b[0m Epoch 0: train loss 0.045275, accuracy 0.478444\n",
      " pid=19244)\u001b[0m Epoch 0: train loss 0.044497, accuracy 0.490667\n",
      " pid=27924)\u001b[0m Epoch 2: train loss 0.038939, accuracy 0.555778\n",
      " pid=27000)\u001b[0m Epoch 1: train loss 0.042404, accuracy 0.507333\n",
      " pid=26956)\u001b[0m [Client 5] fit, config: {}\n",
      " pid=19244)\u001b[0m Epoch 1: train loss 0.041429, accuracy 0.532222\n",
      " pid=27924)\u001b[0m Epoch 3: train loss 0.036637, accuracy 0.575778\n",
      " pid=27000)\u001b[0m Epoch 2: train loss 0.039452, accuracy 0.541556\n",
      " pid=26956)\u001b[0m Epoch 0: train loss 0.045420, accuracy 0.471778\n",
      " pid=19244)\u001b[0m Epoch 2: train loss 0.039223, accuracy 0.550667\n",
      " pid=27924)\u001b[0m Epoch 4: train loss 0.033954, accuracy 0.610000\n",
      " pid=27924)\u001b[0m [Client 3] fit, config: {}\n",
      " pid=26956)\u001b[0m Epoch 1: train loss 0.042540, accuracy 0.507778\n",
      " pid=27000)\u001b[0m Epoch 3: train loss 0.036782, accuracy 0.568444\n",
      " pid=19244)\u001b[0m Epoch 3: train loss 0.037264, accuracy 0.577333\n",
      " pid=27924)\u001b[0m Epoch 0: train loss 0.045387, accuracy 0.479111\n",
      " pid=26956)\u001b[0m Epoch 2: train loss 0.040411, accuracy 0.526889\n",
      " pid=27000)\u001b[0m Epoch 4: train loss 0.034444, accuracy 0.607556\n",
      " pid=27000)\u001b[0m [Client 0] fit, config: {}\n",
      " pid=19244)\u001b[0m Epoch 4: train loss 0.035378, accuracy 0.597111\n",
      " pid=19244)\u001b[0m [Client 6] fit, config: {}\n",
      " pid=27924)\u001b[0m Epoch 1: train loss 0.043059, accuracy 0.508444\n",
      " pid=26956)\u001b[0m Epoch 3: train loss 0.037816, accuracy 0.561333\n",
      " pid=27000)\u001b[0m Epoch 0: train loss 0.044836, accuracy 0.478667\n",
      " pid=19244)\u001b[0m Epoch 0: train loss 0.045431, accuracy 0.476222\n",
      " pid=27924)\u001b[0m Epoch 2: train loss 0.040902, accuracy 0.529556\n",
      " pid=26956)\u001b[0m Epoch 4: train loss 0.036000, accuracy 0.582889\n",
      " pid=26956)\u001b[0m [Client 1] fit, config: {}\n",
      " pid=27000)\u001b[0m Epoch 1: train loss 0.041439, accuracy 0.519556\n",
      " pid=19244)\u001b[0m Epoch 1: train loss 0.042753, accuracy 0.504889\n",
      " pid=27924)\u001b[0m Epoch 3: train loss 0.038742, accuracy 0.561778\n",
      " pid=26956)\u001b[0m Epoch 0: train loss 0.044765, accuracy 0.477111\n",
      " pid=27000)\u001b[0m Epoch 2: train loss 0.039630, accuracy 0.549111\n",
      " pid=19244)\u001b[0m Epoch 2: train loss 0.039737, accuracy 0.540889\n",
      " pid=27924)\u001b[0m Epoch 4: train loss 0.036108, accuracy 0.592000\n",
      " pid=27924)\u001b[0m [Client 2] fit, config: {}\n",
      " pid=26956)\u001b[0m Epoch 1: train loss 0.041456, accuracy 0.520667\n",
      " pid=27000)\u001b[0m Epoch 3: train loss 0.037016, accuracy 0.572889\n",
      " pid=19244)\u001b[0m Epoch 3: train loss 0.037703, accuracy 0.566889\n",
      " pid=27924)\u001b[0m Epoch 0: train loss 0.044930, accuracy 0.484889\n",
      " pid=26956)\u001b[0m Epoch 2: train loss 0.038729, accuracy 0.550667\n",
      " pid=27000)\u001b[0m Epoch 4: train loss 0.034488, accuracy 0.603556\n",
      " pid=27000)\u001b[0m [Client 8] fit, config: {}\n",
      " pid=19244)\u001b[0m Epoch 4: train loss 0.035678, accuracy 0.589556\n",
      " pid=27924)\u001b[0m Epoch 1: train loss 0.042134, accuracy 0.513556\n",
      " pid=26956)\u001b[0m Epoch 3: train loss 0.036701, accuracy 0.566889\n",
      " pid=27000)\u001b[0m Epoch 0: train loss 0.044234, accuracy 0.490444\n",
      " pid=27924)\u001b[0m Epoch 2: train loss 0.039677, accuracy 0.543778\n",
      " pid=26956)\u001b[0m Epoch 4: train loss 0.034288, accuracy 0.606222\n",
      " pid=27000)\u001b[0m Epoch 1: train loss 0.041474, accuracy 0.519111\n",
      " pid=27924)\u001b[0m Epoch 3: train loss 0.037294, accuracy 0.578444\n",
      " pid=27000)\u001b[0m Epoch 2: train loss 0.038999, accuracy 0.553556\n",
      " pid=27924)\u001b[0m Epoch 4: train loss 0.034748, accuracy 0.608222\n",
      " pid=27000)\u001b[0m Epoch 3: train loss 0.036722, accuracy 0.580444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-05-29 11:39:46,728 | server.py:232 | fit_round 3 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-05-29 11:39:46,764 | server.py:168 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pid=27000)\u001b[0m Epoch 4: train loss 0.033772, accuracy 0.621778\n",
      " pid=27000)\u001b[0m [Client 7] evaluate, config: {}\n",
      " pid=27000)\u001b[0m Client 7 loss 0.04311247169971466\n",
      " pid=27000)\u001b[0m Client 7 accuracy 0.518\n",
      " pid=27000)\u001b[0m [Client 2] evaluate, config: {}\n",
      " pid=27924)\u001b[0m [Client 5] evaluate, config: {}\n",
      " pid=27000)\u001b[0m Client 2 loss 0.04556352210044861\n",
      " pid=27000)\u001b[0m Client 2 accuracy 0.5\n",
      " pid=26956)\u001b[0m [Client 3] evaluate, config: {}\n",
      " pid=27924)\u001b[0m Client 5 loss 0.0403660671710968\n",
      " pid=27924)\u001b[0m Client 5 accuracy 0.516\n",
      " pid=26956)\u001b[0m Client 3 loss 0.041824417114257814\n",
      " pid=26956)\u001b[0m Client 3 accuracy 0.554\n",
      " pid=26956)\u001b[0m [Client 6] evaluate, config: {}\n",
      " pid=26956)\u001b[0m Client 6 loss 0.04151818835735321\n",
      " pid=26956)\u001b[0m Client 6 accuracy 0.526\n",
      " pid=26956)\u001b[0m [Client 0] evaluate, config: {}\n",
      " pid=26956)\u001b[0m Client 0 loss 0.04397455382347107\n",
      " pid=26956)\u001b[0m Client 0 accuracy 0.51\n",
      " pid=27924)\u001b[0m [Client 9] evaluate, config: {}\n",
      " pid=27000)\u001b[0m [Client 1] evaluate, config: {}\n",
      " pid=26956)\u001b[0m [Client 4] evaluate, config: {}\n",
      " pid=19244)\u001b[0m [Client 8] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-05-29 11:40:01,820 | server.py:182 | evaluate_round 3 received 10 results and 0 failures\n",
      "INFO flwr 2024-05-29 11:40:01,822 | server.py:147 | FL finished in 197.79143010000007\n",
      "INFO flwr 2024-05-29 11:40:01,824 | app.py:218 | app_fit: losses_distributed [(1, 0.05757532110214233), (2, 0.045601885247230536), (3, 0.042524653851985936)]\n",
      "INFO flwr 2024-05-29 11:40:01,825 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2024-05-29 11:40:01,826 | app.py:220 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2024-05-29 11:40:01,827 | app.py:221 | app_fit: losses_centralized []\n",
      "INFO flwr 2024-05-29 11:40:01,827 | app.py:222 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.05757532110214233\n",
       "\tround 2: 0.045601885247230536\n",
       "\tround 3: 0.042524653851985936"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pid=27924)\u001b[0m Client 9 loss 0.04389840006828308\n",
      " pid=27924)\u001b[0m Client 9 accuracy 0.516\n",
      " pid=27000)\u001b[0m Client 1 loss 0.04200864565372467\n",
      " pid=27000)\u001b[0m Client 1 accuracy 0.526\n",
      " pid=26956)\u001b[0m Client 4 loss 0.042090866446495054\n",
      " pid=26956)\u001b[0m Client 4 accuracy 0.498\n",
      " pid=19244)\u001b[0m Client 8 loss 0.040889406085014346\n",
      " pid=19244)\u001b[0m Client 8 accuracy 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread 2024-05-29 18:33:30,550\tERROR import_thread.py:85 -- ImportThread: <_MultiThreadedRendezvous of RPC that terminated with:\n",
      "\tstatus = StatusCode.UNKNOWN\n",
      "\tdetails = \"Stream removed\"\n",
      "\tdebug_error_string = \"{\"created\":\"@1716987810.545000000\",\"description\":\"Error received from peer ipv4:127.0.0.1:62225\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1075,\"grpc_message\":\"Stream removed\",\"grpc_status\":2}\"\n",
      ">\n",
      "ray_listen_error_messages:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\worker.py\", line 1311, in listen_error_messages_from_gcs\n",
      "    _, error_data = worker.gcs_error_subscriber.poll()\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\gcs_pubsub.py\", line 340, in poll\n",
      "    self._poll_locked(timeout=timeout)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\ray\\_private\\gcs_pubsub.py\", line 270, in _poll_locked\n",
      "    fut.result(timeout=1)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\flwrpytorch\\lib\\site-packages\\grpc\\_channel.py\", line 744, in result\n",
      "    raise self\n",
      "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
      "\tstatus = StatusCode.UNKNOWN\n",
      "\tdetails = \"Stream removed\"\n",
      "\tdebug_error_string = \"{\"created\":\"@1716987810.545000000\",\"description\":\"Error received from peer ipv4:127.0.0.1:62225\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1075,\"grpc_message\":\"Stream removed\",\"grpc_status\":2}\"\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
